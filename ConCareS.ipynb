{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:20:54.787738Z",
     "start_time": "2020-05-09T08:20:53.780563Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import torch.distributions.bernoulli as bernoulli\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import torch.distributions.bernoulli as bernoulli\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Source Data & Model (Concare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:20:54.795387Z",
     "start_time": "2020-05-09T08:20:54.791303Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = './data/Challenge/normalized/'\n",
    "small_part = False\n",
    "arg_timestep = 1.0\n",
    "batch_size = 256\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:20:54.863483Z",
     "start_time": "2020-05-09T08:20:54.798175Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_x = pickle.load(open(data_path + 'x.dat', 'rb'))\n",
    "# all_y = pickle.load(open(data_path + 'y.dat', 'rb'))\n",
    "# all_names = pickle.load(open(data_path + 'name.dat', 'rb'))\n",
    "# # time = pickle.load(open(data_path + 'time', 'rb'))\n",
    "# # weight = pickle.load(open(data_path + 'weight', 'rb'))\n",
    "# static = pickle.load(open(data_path + 'demo.dat', 'rb'))\n",
    "# mask_x = pickle.load(open(data_path + 'mask_x.dat', 'rb'))\n",
    "# mask_demo = pickle.load(open(data_path + 'mask_demo.dat', 'rb'))\n",
    "# all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "# print(all_x[0])\n",
    "# print(mask_x[0])\n",
    "# print(all_names[0])\n",
    "# print(static[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.210811Z",
     "start_time": "2020-05-09T08:20:54.867342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32268\n",
      "4033\n",
      "4035\n",
      "0.07267261683401513\n",
      "0.07265063228365981\n",
      "0.07286245353159851\n"
     ]
    }
   ],
   "source": [
    "train_x = pickle.load(open(data_path + 'train_x.dat', 'rb'))\n",
    "train_y = pickle.load(open(data_path + 'train_y.dat', 'rb'))\n",
    "train_names = pickle.load(open(data_path + 'train_names.dat', 'rb'))\n",
    "train_static = pickle.load(open(data_path + 'train_static.dat', 'rb'))\n",
    "train_x_len = pickle.load(open(data_path + 'train_x_len.dat', 'rb'))\n",
    "train_mask_x = pickle.load(open(data_path + 'train_mask_x.dat', 'rb'))\n",
    "\n",
    "dev_x = pickle.load(open(data_path + 'dev_x.dat', 'rb'))\n",
    "dev_y = pickle.load(open(data_path + 'dev_y.dat', 'rb'))\n",
    "dev_names = pickle.load(open(data_path + 'dev_names.dat', 'rb'))\n",
    "dev_static = pickle.load(open(data_path + 'dev_static.dat', 'rb'))\n",
    "dev_x_len = pickle.load(open(data_path + 'dev_x_len.dat', 'rb'))\n",
    "dev_mask_x = pickle.load(open(data_path + 'dev_mask_x.dat', 'rb'))\n",
    "\n",
    "test_x = pickle.load(open(data_path + 'test_x.dat', 'rb'))\n",
    "test_y = pickle.load(open(data_path + 'test_y.dat', 'rb'))\n",
    "test_names = pickle.load(open(data_path + 'test_names.dat', 'rb'))\n",
    "test_static = pickle.load(open(data_path + 'test_static.dat', 'rb'))\n",
    "test_x_len = pickle.load(open(data_path + 'test_x_len.dat', 'rb'))\n",
    "test_mask_x = pickle.load(open(data_path + 'test_mask_x.dat', 'rb'))\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(dev_x))\n",
    "print(len(test_x))\n",
    "print(sum(train_y)/len(train_y))\n",
    "print(sum(dev_y)/len(dev_y))\n",
    "print(sum(test_y)/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.225470Z",
     "start_time": "2020-05-09T08:21:21.213538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "# device = torch.device('cuda')\n",
    "print(\"available device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.310494Z",
     "start_time": "2020-05-09T08:21:21.228005Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.368290Z",
     "start_time": "2020-05-09T08:21:21.314155Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_re_loss(y_pred, y_true):\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.426499Z",
     "start_time": "2020-05-09T08:21:21.373455Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "\n",
    "    sents_padded = []\n",
    "\n",
    "    max_length = max([len(_) for _ in sents])\n",
    "    for i in sents:\n",
    "        padded = list(i) + [pad_token]*(max_length-len(i))\n",
    "        sents_padded.append(np.array(padded))\n",
    "\n",
    "\n",
    "    return np.array(sents_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.504153Z",
     "start_time": "2020-05-09T08:21:21.429907Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_iter(x, y, mask, lens, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx], mask[idx], lens[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_mask_x = [e[2] for e in examples]\n",
    "#         batch_name = [e[2] for e in examples]\n",
    "        batch_lens = [e[3] for e in examples]\n",
    "\n",
    "        yield batch_x, batch_y, batch_mask_x, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.562401Z",
     "start_time": "2020-05-09T08:21:21.507039Z"
    }
   },
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None):\n",
    "    \"\"\"length: B.\n",
    "    return B x max_len.\n",
    "    If max_len is None, then max of length will be used.\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1, 'Length shape should be 1 dimensional.'\n",
    "    max_len = max_len or length.max().item()\n",
    "    mask = torch.arange(max_len, device=length.device,\n",
    "                        dtype=length.dtype).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "    if dtype is not None:\n",
    "        mask = torch.as_tensor(mask, dtype=dtype, device=length.device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:21.723499Z",
     "start_time": "2020-05-09T08:21:21.566300Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', demographic_dim=12, time_aware=False, use_demographic=False):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "        self.use_demographic = use_demographic\n",
    "        self.demographic_dim = demographic_dim\n",
    "        self.time_aware = time_aware\n",
    "\n",
    "        # batch_time = torch.arange(0, batch_mask.size()[1], dtype=torch.float32).reshape(1, batch_mask.size()[1], 1)\n",
    "        # batch_time = batch_time.repeat(batch_mask.size()[0], 1, 1)\n",
    "        \n",
    "        if attention_type == 'add':\n",
    "            if self.time_aware == True:\n",
    "                # self.Wx = nn.Parameter(torch.randn(attention_input_dim+1, attention_hidden_dim))\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "                self.Wtime_aware = nn.Parameter(torch.randn(1, attention_hidden_dim))\n",
    "                nn.init.kaiming_uniform_(self.Wtime_aware, a=math.sqrt(5))\n",
    "            else:\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wd = nn.Parameter(torch.randn(demographic_dim, attention_hidden_dim))\n",
    "            self.bh = nn.Parameter(torch.zeros(attention_hidden_dim,))\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wd, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'mul':\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_input_dim, attention_input_dim))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'concat':\n",
    "            if self.time_aware == True:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim+1, attention_hidden_dim))\n",
    "            else:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        else:\n",
    "            raise RuntimeError('Wrong attention type.')\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, input, demo=None):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * time_step * hidden_dim(i)\n",
    "        #assert(input_dim == self.input_dim)\n",
    "\n",
    "        # time_decays = torch.zeros((time_step,time_step)).to(device)# t*t\n",
    "        # for this_time in range(time_step):\n",
    "        #     for pre_time in range(time_step):\n",
    "        #         if pre_time > this_time:\n",
    "        #             break\n",
    "        #         time_decays[this_time][pre_time] = torch.tensor(this_time - pre_time, dtype=torch.float32).to(device)\n",
    "        # b_time_decays = tile(time_decays, 0, batch_size).view(batch_size,time_step,time_step).unsqueeze(-1).to(device)# b t t 1\n",
    "\n",
    "        time_decays = torch.tensor(range(time_step-1,-1,-1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)# 1*t*1\n",
    "        b_time_decays = time_decays.repeat(batch_size,1,1)# b t 1\n",
    "        \n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
    "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            if self.time_aware == True:\n",
    "                # k_input = torch.cat((input, time), dim=-1)\n",
    "                k = torch.matmul(input, self.Wx)#b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "                time_hidden = torch.matmul(b_time_decays, self.Wtime_aware)#  b t h\n",
    "            else:\n",
    "                k = torch.matmul(input, self.Wx)# b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "            if self.use_demographic == True:\n",
    "                d = torch.matmul(demo, self.Wd) #B*H\n",
    "                d = torch.reshape(d, (batch_size, 1, self.attention_hidden_dim)) # b 1 h\n",
    "            h = q + k + self.bh # b t h\n",
    "            if self.time_aware == True:\n",
    "                h += time_hidden\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "        elif self.attention_type == 'mul':\n",
    "            e = torch.matmul(input[:,-1,:], self.Wa)#b i\n",
    "            e = torch.matmul(e.unsqueeze(1), input.permute(0,2,1)).squeeze() + self.ba #b t\n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input[:,-1,:].unsqueeze(1).repeat(1,time_step,1)# b t i\n",
    "            k = input\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            if self.time_aware == True:\n",
    "                c = torch.cat((c, b_time_decays), dim=-1) #B*T*2I+1\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        # e = torch.exp(e - torch.max(e, dim=-1, keepdim=True).values)\n",
    "        \n",
    "        # if self.attention_width is not None:\n",
    "        #     if self.history_only:\n",
    "        #         lower = torch.arange(0, time_step).to(device) - (self.attention_width - 1)\n",
    "        #     else:\n",
    "        #         lower = torch.arange(0, time_step).to(device) - self.attention_width // 2\n",
    "        #     lower = lower.unsqueeze(-1)\n",
    "        #     upper = lower + self.attention_width\n",
    "        #     indices = torch.arange(0, time_step).unsqueeze(0).to(device)\n",
    "        #     e = e * (lower <= indices).float() * (indices < upper).float()\n",
    "        \n",
    "        # s = torch.sum(e, dim=-1, keepdim=True)\n",
    "        # mask = subsequent_mask(time_step).to(device) # 1 t t 下三角\n",
    "        # scores = e.masked_fill(mask == 0, -1e9)# b t t 下三角\n",
    "        a = self.softmax(e) #B*T\n",
    "        v = torch.matmul(a.unsqueeze(1), input).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "class FinalAttentionQKV(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', dropout=None):\n",
    "        super(FinalAttentionQKV, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "\n",
    "\n",
    "        self.W_q = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_k = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_v = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "\n",
    "        self.W_out = nn.Linear(attention_hidden_dim, 1)\n",
    "\n",
    "        self.b_in = nn.Parameter(torch.zeros(1,))\n",
    "        self.b_out = nn.Parameter(torch.zeros(1,))\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.W_q.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_k.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_v.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_out.weight, a=math.sqrt(5))\n",
    "\n",
    "        self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "        self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "        self.ba = nn.Parameter(torch.zeros(1,))\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * input_dim + 1 * hidden_dim(i)\n",
    "        input_q = self.W_q(torch.mean(input,1)) # b h\n",
    "        input_k = self.W_k(input)# b t h\n",
    "        input_v = self.W_v(input)# b t h\n",
    "\n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "\n",
    "            q = torch.reshape(input_q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            h = q + input_k + self.b_in # b t h\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = self.W_out(h) # b t 1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "\n",
    "        elif self.attention_type == 'mul':\n",
    "            q = torch.reshape(input_q, (batch_size, self.attention_hidden_dim, 1)) #B*h 1\n",
    "            e = torch.matmul(input_k, q).squeeze()#b t\n",
    "            \n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input_q.unsqueeze(1).repeat(1,time_step,1)# b t h\n",
    "            k = input_k\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        a = self.softmax(e) #B*T\n",
    "        if self.dropout is not None:\n",
    "            a = self.dropout(a)\n",
    "        v = torch.matmul(a.unsqueeze(1), input_v).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)])).to(device)\n",
    "    return torch.index_select(a, dim, order_index).to(device)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module): # new added\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x)))), None\n",
    "\n",
    "# class PositionwiseFeedForwardConv(nn.Module):\n",
    "\n",
    "#     def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0):\n",
    "#         super(PositionalWiseFeedForward, self).__init__()\n",
    "#         self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
    "#         self.w2 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.layer_norm = nn.LayerNorm(model_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output = x.transpose(1, 2)\n",
    "#         output = self.w2(F.relu(self.w1(output)))\n",
    "#         output = self.dropout(output.transpose(1, 2))\n",
    "\n",
    "#         # add residual and norm layer\n",
    "#         output = self.layer_norm(x + output)\n",
    "#         return output\n",
    "\n",
    "class PositionalEncoding(nn.Module): # new added / not use anymore\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=400):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0 # 下三角矩阵\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)# b h t d_k\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k) # b h t t\n",
    "    if mask is not None:# 1 1 t t\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)# b h t t 下三角\n",
    "    p_attn = F.softmax(scores, dim = -1)# b h t t\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn # b h t v (d_k) \n",
    "    \n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, self.d_k * self.h), 3)\n",
    "        self.final_linear = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "        self.mask = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1) # 1 1 t t\n",
    "\n",
    "        nbatches = query.size(0)# b\n",
    "        input_dim = query.size(1)# i+1\n",
    "        feature_dim = query.size(-1)# i+1\n",
    "\n",
    "        #input size -> # batch_size * d_input * hidden_dim\n",
    "        \n",
    "        # d_model => h * d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))] # b num_head d_input d_k\n",
    "        \n",
    "        \n",
    "        querys = []\n",
    "        keys = []\n",
    "        values = []\n",
    "        for i in range(self.h):\n",
    "            querys.append(query[:,i].unsqueeze(1))\n",
    "            keys.append(key[:,i].unsqueeze(1))\n",
    "            values.append(value[:,i].unsqueeze(1))\n",
    "            \n",
    "        \n",
    "       \n",
    "        if self.training == True:\n",
    "\n",
    "            x, attn = attention(querys[0], keys[0], values[0], mask=mask, \n",
    "                                     dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
    "\n",
    "\n",
    "            self.attn = attn\n",
    "    #         self.mask = mask\n",
    "            attn1 = torch.mean(attn[:,0],1)\n",
    "    #         print(attn1.shape) # 256, 153\n",
    "    #         attn1_p = attn1/torch.sum(attn1,1).unsqueeze(1)\n",
    "\n",
    "            attn1_p = 0.1*self.sigmoid(lNorm(attn1)*0.01)\n",
    "    #         print(attn1_p.shape)\n",
    "\n",
    "\n",
    "            dis_b1 = bernoulli.Bernoulli(attn1_p)\n",
    "            to_mask1 = 1 - dis_b1.sample().to(device)\n",
    "            mask1 = to_mask1.unsqueeze(1).repeat(1,input_dim,1).unsqueeze(1)\n",
    "\n",
    "\n",
    "            tempx, attn = attention(querys[1], keys[1], values[1], mask=mask1, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            self.mask = mask1\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "            attn2 = attn1 + torch.mean(attn[:,0],1)\n",
    "    #         attn2_p = attn2/torch.sum(attn2,1).unsqueeze(1)\n",
    "            attn2_p = 0.1*self.sigmoid(lNorm(attn2)*0.01)\n",
    "\n",
    "            dis_b2 = bernoulli.Bernoulli(attn2_p)\n",
    "            to_mask2 = 1 - dis_b2.sample().to(device)\n",
    "            mask2 = to_mask2.unsqueeze(1).repeat(1,input_dim,1).unsqueeze(1)\n",
    "\n",
    "            tempx, attn = attention(querys[2], keys[2], values[2], mask=mask2, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            self.mask = torch.cat((self.mask, mask2), 1)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "    #         attn3 = torch.mean(attn[:,0],0)\n",
    "            attn3 = attn2 + torch.mean(attn[:,0],1)\n",
    "    #         attn3_p = attn3/torch.sum(attn3,1).unsqueeze(1)\n",
    "            attn3_p = 0.1*self.sigmoid(lNorm(attn3)*0.01)\n",
    "\n",
    "            dis_b3 = bernoulli.Bernoulli(attn3_p)\n",
    "            to_mask3 = 1 - dis_b3.sample().to(device)\n",
    "            mask3 = to_mask3.unsqueeze(1).repeat(1,input_dim,1).unsqueeze(1)\n",
    "\n",
    "\n",
    "            tempx, attn = attention(querys[3], keys[3], values[3], mask=mask3, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            self.mask = torch.cat((self.mask, mask3), 1)\n",
    "\n",
    "    #         attn4 = torch.mean(attn[0,0],0)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "    \n",
    "        \n",
    "\n",
    "        if self.training == False:\n",
    "# #             print(1)\n",
    "            \n",
    "            x, attn = attention(querys[0], keys[0], values[0], mask=None, \n",
    "                                     dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
    "\n",
    "\n",
    "            self.attn = attn\n",
    "\n",
    "            tempx, attn = attention(querys[1], keys[1], values[1], mask=None, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "\n",
    "\n",
    "            tempx, attn = attention(querys[2], keys[2], values[2], mask=None, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            tempx, attn = attention(querys[3], keys[3], values[3], mask=None, \n",
    "                                     dropout=self.dropout)\n",
    "            self.attn = torch.cat((self.attn, attn), 1)\n",
    "\n",
    "    #         attn4 = torch.mean(attn[0,0],0)\n",
    "            x = torch.cat((x, tempx),1)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)# batch_size * d_input * hidden_dim\n",
    "\n",
    "        return self.final_linear(x), torch.zeros(1).to(device)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-7):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "def lNorm(x):\n",
    "    mean = x.mean(-1, keepdim=True)\n",
    "    std = x.std(-1, keepdim=True)\n",
    "    eps = 1e-7\n",
    "    return (x - mean) / (std + eps)\n",
    "\n",
    "def cov(m, y=None):\n",
    "    if y is not None:\n",
    "        m = torch.cat((m, y), dim=0)\n",
    "    m_exp = torch.mean(m, dim=1)\n",
    "    x = m - m_exp[:, None]\n",
    "    cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
    "    return cov\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        returned_value = sublayer(self.norm(x))\n",
    "        return x + self.dropout(returned_value[0]) , returned_value[1]\n",
    "\n",
    "class vanilla_transformer_encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(vanilla_transformer_encoder, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "  \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, lens):\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "#         demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "     \n",
    "        GRU_embeded_input = self.GRUs[0](pack_padded_sequence(input[:,:,0].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.GRUs[i+1](pack_padded_sequence(input[:,:,i+1].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "            GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
    "            \n",
    "\n",
    "        contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "    \n",
    "        DeCov_loss = contexts[1]\n",
    "        contexts = contexts[0]\n",
    "\n",
    "        contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "        \n",
    "\n",
    "        weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
    "        output = self.output(self.dropout(weighted_contexts))# b 1\n",
    "        output = self.sigmoid(output)\n",
    "#         print(weighted_contexts.shape)\n",
    "          \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:29.271914Z",
     "start_time": "2020-05-09T08:21:21.726418Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED) #numpy\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED) # cpu\n",
    "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "    \n",
    "epochs = 150\n",
    "batch_size = 256\n",
    "input_dim = 33\n",
    "hidden_dim = 32\n",
    "d_model = 32\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1\n",
    "\n",
    "model = vanilla_transformer_encoder(input_dim = input_dim, hidden_dim = hidden_dim, d_model = d_model,  MHD_num_head = MHD_num_head , d_ff = d_ff, output_dim = output_dim).to(device)\n",
    "# input_dim, d_model, d_k, d_v, MHD_num_head, d_ff, output_dim\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T04:38:38.601576Z",
     "start_time": "2020-05-09T08:21:29.275170Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 0: Train Loss = 0.6263\n",
      "Epoch 0 Batch 20: Train Loss = 0.3647\n",
      "Epoch 0 Batch 40: Train Loss = 0.3235\n",
      "Epoch 0 Batch 60: Train Loss = 0.3648\n",
      "Epoch 0 Batch 80: Train Loss = 0.2472\n",
      "Epoch 0 Batch 100: Train Loss = 0.2660\n",
      "Epoch 0 Batch 120: Train Loss = 0.2637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.3021 Valid loss = 0.2574 roc = 0.7276\n",
      "confusion matrix:\n",
      "[[3918    0]\n",
      " [ 308    0]]\n",
      "accuracy = 0.9271178245544434\n",
      "precision class 0 = 0.9271178245544434\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7276282293510472\n",
      "AUC of PRC = 0.2362470339138863\n",
      "min(+P, Se) = 0.32142857142857145\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7276 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 1 Batch 0: Train Loss = 0.2744\n",
      "Epoch 1 Batch 20: Train Loss = 0.2491\n",
      "Epoch 1 Batch 40: Train Loss = 0.2580\n",
      "Epoch 1 Batch 60: Train Loss = 0.2182\n",
      "Epoch 1 Batch 80: Train Loss = 0.2777\n",
      "Epoch 1 Batch 100: Train Loss = 0.2307\n",
      "Epoch 1 Batch 120: Train Loss = 0.2535\n",
      "Epoch 1: Loss = 0.2649 Valid loss = 0.2420 roc = 0.7467\n",
      "confusion matrix:\n",
      "[[3918    0]\n",
      " [ 308    0]]\n",
      "accuracy = 0.9271178245544434\n",
      "precision class 0 = 0.9271178245544434\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.746653805612458\n",
      "AUC of PRC = 0.1770576443738946\n",
      "min(+P, Se) = 0.22727272727272727\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7467 ------------\n",
      "Epoch 2 Batch 0: Train Loss = 0.2889\n",
      "Epoch 2 Batch 20: Train Loss = 0.2042\n",
      "Epoch 2 Batch 40: Train Loss = 0.3233\n",
      "Epoch 2 Batch 60: Train Loss = 0.3066\n",
      "Epoch 2 Batch 80: Train Loss = 0.2719\n",
      "Epoch 2 Batch 100: Train Loss = 0.1633\n",
      "Epoch 2 Batch 120: Train Loss = 0.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/choczhang/EMR/challenge/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score=2*prec1*rec1/(prec1+rec1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.2502 Valid loss = 0.2211 roc = 0.7954\n",
      "confusion matrix:\n",
      "[[3917    1]\n",
      " [ 308    0]]\n",
      "accuracy = 0.9268811941146851\n",
      "precision class 0 = 0.9271005988121033\n",
      "precision class 1 = 0.0\n",
      "recall class 0 = 0.9997447729110718\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7954263704646554\n",
      "AUC of PRC = 0.260372203472149\n",
      "min(+P, Se) = 0.2890625\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7954 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 3 Batch 0: Train Loss = 0.2711\n",
      "Epoch 3 Batch 20: Train Loss = 0.2032\n",
      "Epoch 3 Batch 40: Train Loss = 0.3228\n",
      "Epoch 3 Batch 60: Train Loss = 0.2491\n",
      "Epoch 3 Batch 80: Train Loss = 0.2368\n",
      "Epoch 3 Batch 100: Train Loss = 0.2030\n",
      "Epoch 3 Batch 120: Train Loss = 0.2423\n",
      "Epoch 3: Loss = 0.2294 Valid loss = 0.2012 roc = 0.8338\n",
      "confusion matrix:\n",
      "[[3907   11]\n",
      " [ 274   34]]\n",
      "accuracy = 0.9325603246688843\n",
      "precision class 0 = 0.9344654679298401\n",
      "precision class 1 = 0.7555555701255798\n",
      "recall class 0 = 0.9971924424171448\n",
      "recall class 1 = 0.11038961261510849\n",
      "AUC of ROC = 0.8338479412369151\n",
      "AUC of PRC = 0.38956294351001974\n",
      "min(+P, Se) = 0.4253246753246753\n",
      "f1_score = 0.192634569740855\n",
      "------------ Save best model - AUROC: 0.8338 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 4 Batch 0: Train Loss = 0.2303\n",
      "Epoch 4 Batch 20: Train Loss = 0.2297\n",
      "Epoch 4 Batch 40: Train Loss = 0.1877\n",
      "Epoch 4 Batch 60: Train Loss = 0.2020\n",
      "Epoch 4 Batch 80: Train Loss = 0.2017\n",
      "Epoch 4 Batch 100: Train Loss = 0.2113\n",
      "Epoch 4 Batch 120: Train Loss = 0.2468\n",
      "Epoch 4: Loss = 0.2113 Valid loss = 0.1853 roc = 0.8646\n",
      "confusion matrix:\n",
      "[[3868   50]\n",
      " [ 225   83]]\n",
      "accuracy = 0.9349266290664673\n",
      "precision class 0 = 0.9450281262397766\n",
      "precision class 1 = 0.6240601539611816\n",
      "recall class 0 = 0.9872384071350098\n",
      "recall class 1 = 0.26948052644729614\n",
      "AUC of ROC = 0.8645512221316203\n",
      "AUC of PRC = 0.4645158707271273\n",
      "min(+P, Se) = 0.4772727272727273\n",
      "f1_score = 0.3764172410087941\n",
      "------------ Save best model - AUROC: 0.8646 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 5 Batch 0: Train Loss = 0.1959\n",
      "Epoch 5 Batch 20: Train Loss = 0.1903\n",
      "Epoch 5 Batch 40: Train Loss = 0.1725\n",
      "Epoch 5 Batch 60: Train Loss = 0.2346\n",
      "Epoch 5 Batch 80: Train Loss = 0.1357\n",
      "Epoch 5 Batch 100: Train Loss = 0.1876\n",
      "Epoch 5 Batch 120: Train Loss = 0.2038\n",
      "Epoch 5: Loss = 0.1919 Valid loss = 0.1902 roc = 0.8664\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 228   80]]\n",
      "accuracy = 0.9375295639038086\n",
      "precision class 0 = 0.9445255398750305\n",
      "precision class 1 = 0.6896551847457886\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.25974026322364807\n",
      "AUC of ROC = 0.866444747187473\n",
      "AUC of PRC = 0.48309845434516474\n",
      "min(+P, Se) = 0.48264984227129337\n",
      "f1_score = 0.3773585079339276\n",
      "------------ Save best model - AUROC: 0.8664 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 6 Batch 0: Train Loss = 0.2011\n",
      "Epoch 6 Batch 20: Train Loss = 0.2533\n",
      "Epoch 6 Batch 40: Train Loss = 0.2255\n",
      "Epoch 6 Batch 60: Train Loss = 0.2750\n",
      "Epoch 6 Batch 80: Train Loss = 0.1369\n",
      "Epoch 6 Batch 100: Train Loss = 0.2077\n",
      "Epoch 6 Batch 120: Train Loss = 0.1588\n",
      "Epoch 6: Loss = 0.1940 Valid loss = 0.1787 roc = 0.8828\n",
      "confusion matrix:\n",
      "[[3855   63]\n",
      " [ 213   95]]\n",
      "accuracy = 0.934689998626709\n",
      "precision class 0 = 0.9476401209831238\n",
      "precision class 1 = 0.6012658476829529\n",
      "recall class 0 = 0.9839203953742981\n",
      "recall class 1 = 0.30844154953956604\n",
      "AUC of ROC = 0.8828467346844069\n",
      "AUC of PRC = 0.5007795139493975\n",
      "min(+P, Se) = 0.4967532467532468\n",
      "f1_score = 0.4077253064780936\n",
      "------------ Save best model - AUROC: 0.8828 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 7 Batch 0: Train Loss = 0.1393\n",
      "Epoch 7 Batch 20: Train Loss = 0.1825\n",
      "Epoch 7 Batch 40: Train Loss = 0.1976\n",
      "Epoch 7 Batch 60: Train Loss = 0.1191\n",
      "Epoch 7 Batch 80: Train Loss = 0.2093\n",
      "Epoch 7 Batch 100: Train Loss = 0.1876\n",
      "Epoch 7 Batch 120: Train Loss = 0.1655\n",
      "Epoch 7: Loss = 0.1811 Valid loss = 0.1715 roc = 0.9034\n",
      "confusion matrix:\n",
      "[[3865   53]\n",
      " [ 200  108]]\n",
      "accuracy = 0.9401324987411499\n",
      "precision class 0 = 0.9507995247840881\n",
      "precision class 1 = 0.6708074808120728\n",
      "recall class 0 = 0.9864726662635803\n",
      "recall class 1 = 0.350649356842041\n",
      "AUC of ROC = 0.9034012184854452\n",
      "AUC of PRC = 0.5590597401132881\n",
      "min(+P, Se) = 0.551948051948052\n",
      "f1_score = 0.46055438280052474\n",
      "------------ Save best model - AUROC: 0.9034 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 8 Batch 0: Train Loss = 0.1544\n",
      "Epoch 8 Batch 20: Train Loss = 0.2281\n",
      "Epoch 8 Batch 40: Train Loss = 0.3005\n",
      "Epoch 8 Batch 60: Train Loss = 0.1856\n",
      "Epoch 8 Batch 80: Train Loss = 0.1608\n",
      "Epoch 8 Batch 100: Train Loss = 0.1321\n",
      "Epoch 9 Batch 20: Train Loss = 0.1552\n",
      "Epoch 9 Batch 40: Train Loss = 0.1663\n",
      "Epoch 9 Batch 60: Train Loss = 0.1385\n",
      "Epoch 9 Batch 80: Train Loss = 0.1308\n",
      "Epoch 9 Batch 100: Train Loss = 0.1653\n",
      "Epoch 9 Batch 120: Train Loss = 0.1825\n",
      "Epoch 9: Loss = 0.1561 Valid loss = 0.1463 roc = 0.9183\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 161  147]]\n",
      "accuracy = 0.9507808685302734\n",
      "precision class 0 = 0.9600694179534912\n",
      "precision class 1 = 0.7577319741249084\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.47727271914482117\n",
      "AUC of ROC = 0.9182552388907672\n",
      "AUC of PRC = 0.6577402243326136\n",
      "min(+P, Se) = 0.6168831168831169\n",
      "f1_score = 0.5856573831198532\n",
      "Epoch 10 Batch 0: Train Loss = 0.1317\n",
      "Epoch 10 Batch 20: Train Loss = 0.1318\n",
      "Epoch 10 Batch 40: Train Loss = 0.1545\n",
      "Epoch 10 Batch 60: Train Loss = 0.1549\n",
      "Epoch 10 Batch 80: Train Loss = 0.1539\n",
      "Epoch 10 Batch 100: Train Loss = 0.0945\n",
      "Epoch 10 Batch 120: Train Loss = 0.1201\n",
      "Epoch 10: Loss = 0.1551 Valid loss = 0.1454 roc = 0.9241\n",
      "confusion matrix:\n",
      "[[3859   59]\n",
      " [ 147  161]]\n",
      "accuracy = 0.95125412940979\n",
      "precision class 0 = 0.9633050560951233\n",
      "precision class 1 = 0.7318181991577148\n",
      "recall class 0 = 0.984941303730011\n",
      "recall class 1 = 0.5227272510528564\n",
      "AUC of ROC = 0.9240750316554298\n",
      "AUC of PRC = 0.6802198881491676\n",
      "min(+P, Se) = 0.6298701298701299\n",
      "f1_score = 0.609848476118511\n",
      "------------ Save best model - AUROC: 0.9241 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 11 Batch 0: Train Loss = 0.1450\n",
      "Epoch 11 Batch 20: Train Loss = 0.1519\n",
      "Epoch 11 Batch 40: Train Loss = 0.1275\n",
      "Epoch 11 Batch 60: Train Loss = 0.1759\n",
      "Epoch 11 Batch 80: Train Loss = 0.1264\n",
      "Epoch 11 Batch 100: Train Loss = 0.2229\n",
      "Epoch 11 Batch 120: Train Loss = 0.1562\n",
      "Epoch 11: Loss = 0.1527 Valid loss = 0.1385 roc = 0.9297\n",
      "confusion matrix:\n",
      "[[3826   92]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9491244554519653\n",
      "precision class 0 = 0.9688528776168823\n",
      "precision class 1 = 0.667870044708252\n",
      "recall class 0 = 0.9765186309814453\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.929716659042846\n",
      "AUC of PRC = 0.6956050297378504\n",
      "min(+P, Se) = 0.6201298701298701\n",
      "f1_score = 0.6324786397713951\n",
      "------------ Save best model - AUROC: 0.9297 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 12 Batch 0: Train Loss = 0.1594\n",
      "Epoch 12 Batch 20: Train Loss = 0.1649\n",
      "Epoch 12 Batch 40: Train Loss = 0.1379\n",
      "Epoch 12 Batch 60: Train Loss = 0.1434\n",
      "Epoch 12 Batch 80: Train Loss = 0.2050\n",
      "Epoch 12 Batch 100: Train Loss = 0.1323\n",
      "Epoch 12 Batch 120: Train Loss = 0.1794\n",
      "Epoch 12: Loss = 0.1470 Valid loss = 0.1358 roc = 0.9304\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 146  162]]\n",
      "accuracy = 0.9548035860061646\n",
      "precision class 0 = 0.9636725783348083\n",
      "precision class 1 = 0.782608687877655\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.5259740352630615\n",
      "AUC of ROC = 0.9303742135863116\n",
      "AUC of PRC = 0.697761358848027\n",
      "min(+P, Se) = 0.6580645161290323\n",
      "f1_score = 0.6291261890689875\n",
      "------------ Save best model - AUROC: 0.9304 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 13 Batch 0: Train Loss = 0.0823\n",
      "Epoch 13 Batch 20: Train Loss = 0.1664\n",
      "Epoch 13 Batch 40: Train Loss = 0.1098\n",
      "Epoch 13 Batch 60: Train Loss = 0.1637\n",
      "Epoch 13 Batch 80: Train Loss = 0.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 100: Train Loss = 0.1429\n",
      "Epoch 13 Batch 120: Train Loss = 0.0802\n",
      "Epoch 13: Loss = 0.1404 Valid loss = 0.1383 roc = 0.9324\n",
      "confusion matrix:\n",
      "[[3852   66]\n",
      " [ 130  178]]\n",
      "accuracy = 0.953620433807373\n",
      "precision class 0 = 0.967353105545044\n",
      "precision class 1 = 0.7295082211494446\n",
      "recall class 0 = 0.9831546545028687\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.9323700801495595\n",
      "AUC of PRC = 0.7120213943889445\n",
      "min(+P, Se) = 0.6590909090909091\n",
      "f1_score = 0.6449275925314207\n",
      "------------ Save best model - AUROC: 0.9324 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 14 Batch 0: Train Loss = 0.1853\n",
      "Epoch 14 Batch 20: Train Loss = 0.1081\n",
      "Epoch 14 Batch 40: Train Loss = 0.1112\n",
      "Epoch 14 Batch 60: Train Loss = 0.1058\n",
      "Epoch 14 Batch 80: Train Loss = 0.1449\n",
      "Epoch 14 Batch 100: Train Loss = 0.1453\n",
      "Epoch 14 Batch 120: Train Loss = 0.1458\n",
      "Epoch 14: Loss = 0.1417 Valid loss = 0.1353 roc = 0.9337\n",
      "confusion matrix:\n",
      "[[3836   82]\n",
      " [ 113  195]]\n",
      "accuracy = 0.9538570642471313\n",
      "precision class 0 = 0.9713851809501648\n",
      "precision class 1 = 0.7039711475372314\n",
      "recall class 0 = 0.9790709614753723\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.9336885039411839\n",
      "AUC of PRC = 0.719030364728404\n",
      "min(+P, Se) = 0.6731391585760518\n",
      "f1_score = 0.6666666595550401\n",
      "------------ Save best model - AUROC: 0.9337 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 15 Batch 0: Train Loss = 0.1240\n",
      "Epoch 15 Batch 20: Train Loss = 0.1711\n",
      "Epoch 15 Batch 40: Train Loss = 0.1136\n",
      "Epoch 15 Batch 60: Train Loss = 0.1397\n",
      "Epoch 15 Batch 80: Train Loss = 0.1753\n",
      "Epoch 15 Batch 100: Train Loss = 0.1331\n",
      "Epoch 15 Batch 120: Train Loss = 0.1185\n",
      "Epoch 15: Loss = 0.1392 Valid loss = 0.1365 roc = 0.9351\n",
      "confusion matrix:\n",
      "[[3820   98]\n",
      " [ 109  199]]\n",
      "accuracy = 0.9510174989700317\n",
      "precision class 0 = 0.9722575545310974\n",
      "precision class 1 = 0.6700336933135986\n",
      "recall class 0 = 0.9749872088432312\n",
      "recall class 1 = 0.6461039185523987\n",
      "AUC of ROC = 0.9351237710732351\n",
      "AUC of PRC = 0.7135654317886788\n",
      "min(+P, Se) = 0.6549520766773163\n",
      "f1_score = 0.6578512923185504\n",
      "------------ Save best model - AUROC: 0.9351 ------------\n",
      "Epoch 16 Batch 0: Train Loss = 0.1805\n",
      "Epoch 16 Batch 20: Train Loss = 0.1256\n",
      "Epoch 16 Batch 40: Train Loss = 0.1616\n",
      "Epoch 16 Batch 60: Train Loss = 0.1267\n",
      "Epoch 16 Batch 80: Train Loss = 0.1541\n",
      "Epoch 16 Batch 100: Train Loss = 0.1907\n",
      "Epoch 16 Batch 120: Train Loss = 0.1354\n",
      "Epoch 16: Loss = 0.1398 Valid loss = 0.1334 roc = 0.9346\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 137  171]]\n",
      "accuracy = 0.9569332599639893\n",
      "precision class 0 = 0.9658353924751282\n",
      "precision class 1 = 0.7916666865348816\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.5551947951316833\n",
      "AUC of ROC = 0.9345768447988969\n",
      "AUC of PRC = 0.7173557605514692\n",
      "min(+P, Se) = 0.6645367412140575\n",
      "f1_score = 0.6526717555237413\n",
      "Epoch 17 Batch 0: Train Loss = 0.1041\n",
      "Epoch 17 Batch 20: Train Loss = 0.1203\n",
      "Epoch 17 Batch 40: Train Loss = 0.1482\n",
      "Epoch 17 Batch 60: Train Loss = 0.2458\n",
      "Epoch 17 Batch 80: Train Loss = 0.1298\n",
      "Epoch 17 Batch 100: Train Loss = 0.1735\n",
      "Epoch 17 Batch 120: Train Loss = 0.1708\n",
      "Epoch 17: Loss = 0.1367 Valid loss = 0.1311 roc = 0.9365\n",
      "confusion matrix:\n",
      "[[3858   60]\n",
      " [ 119  189]]\n",
      "accuracy = 0.9576431512832642\n",
      "precision class 0 = 0.9700779318809509\n",
      "precision class 1 = 0.759036123752594\n",
      "recall class 0 = 0.9846860766410828\n",
      "recall class 1 = 0.6136363744735718\n",
      "AUC of ROC = 0.9365366639486089\n",
      "AUC of PRC = 0.7272066737754035\n",
      "min(+P, Se) = 0.6731391585760518\n",
      "f1_score = 0.6786355164119543\n",
      "------------ Save best model - AUROC: 0.9365 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 18 Batch 0: Train Loss = 0.1094\n",
      "Epoch 18 Batch 20: Train Loss = 0.1276\n",
      "Epoch 18 Batch 40: Train Loss = 0.2148\n",
      "Epoch 18 Batch 60: Train Loss = 0.1157\n",
      "Epoch 18 Batch 80: Train Loss = 0.1440\n",
      "Epoch 18 Batch 100: Train Loss = 0.1070\n",
      "Epoch 18 Batch 120: Train Loss = 0.1498\n",
      "Epoch 18: Loss = 0.1353 Valid loss = 0.1319 roc = 0.9382\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 135  173]]\n",
      "accuracy = 0.9576431512832642\n",
      "precision class 0 = 0.9663257598876953\n",
      "precision class 1 = 0.7972350120544434\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.5616883039474487\n",
      "AUC of ROC = 0.938234621427577\n",
      "AUC of PRC = 0.7250455889046982\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6590476099650066\n",
      "------------ Save best model - AUROC: 0.9382 ------------\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 19 Batch 0: Train Loss = 0.0553\n",
      "Epoch 19 Batch 20: Train Loss = 0.1246\n",
      "Epoch 19 Batch 40: Train Loss = 0.1520\n",
      "Epoch 19 Batch 60: Train Loss = 0.1124\n",
      "Epoch 19 Batch 80: Train Loss = 0.1444\n",
      "Epoch 19 Batch 100: Train Loss = 0.0980\n",
      "Epoch 19 Batch 120: Train Loss = 0.1079\n",
      "Epoch 19: Loss = 0.1352 Valid loss = 0.1275 roc = 0.9376\n",
      "confusion matrix:\n",
      "[[3855   63]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9571698904037476\n",
      "precision class 0 = 0.9702995419502258\n",
      "precision class 1 = 0.7509881258010864\n",
      "recall class 0 = 0.9839203953742981\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9375824532792373\n",
      "AUC of PRC = 0.7376161199326996\n",
      "min(+P, Se) = 0.6753246753246753\n",
      "f1_score = 0.6773618068753746\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 20 Batch 0: Train Loss = 0.1118\n",
      "Epoch 20 Batch 20: Train Loss = 0.1095\n",
      "Epoch 20 Batch 40: Train Loss = 0.1157\n",
      "Epoch 20 Batch 60: Train Loss = 0.1612\n",
      "Epoch 20 Batch 80: Train Loss = 0.1340\n",
      "Epoch 20 Batch 100: Train Loss = 0.1694\n",
      "Epoch 20 Batch 120: Train Loss = 0.1277\n",
      "Epoch 20: Loss = 0.1349 Valid loss = 0.1282 roc = 0.9372\n",
      "confusion matrix:\n",
      "[[3859   59]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9569332599639893\n",
      "precision class 0 = 0.9691110253334045\n",
      "precision class 1 = 0.7581967115402222\n",
      "recall class 0 = 0.984941303730011\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9371739159258302\n",
      "AUC of PRC = 0.7319082621530338\n",
      "min(+P, Se) = 0.6763754045307443\n",
      "f1_score = 0.6702898551100217\n",
      "Epoch 21 Batch 0: Train Loss = 0.1172\n",
      "Epoch 21 Batch 20: Train Loss = 0.1584\n",
      "Epoch 21 Batch 40: Train Loss = 0.0822\n",
      "Epoch 21 Batch 60: Train Loss = 0.1328\n",
      "Epoch 21 Batch 80: Train Loss = 0.1546\n",
      "Epoch 21 Batch 100: Train Loss = 0.0925\n",
      "Epoch 21 Batch 120: Train Loss = 0.2002\n",
      "Epoch 21: Loss = 0.1339 Valid loss = 0.1247 roc = 0.9403\n",
      "confusion matrix:\n",
      "[[3878   40]\n",
      " [ 138  170]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.9656374454498291\n",
      "precision class 1 = 0.8095238208770752\n",
      "recall class 0 = 0.9897907376289368\n",
      "recall class 1 = 0.551948070526123\n",
      "AUC of ROC = 0.9403419449361257\n",
      "AUC of PRC = 0.7423092637983623\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6563706732388392\n",
      "------------ Save best model - AUROC: 0.9403 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 22 Batch 0: Train Loss = 0.2250\n",
      "Epoch 22 Batch 20: Train Loss = 0.1177\n",
      "Epoch 22 Batch 40: Train Loss = 0.1337\n",
      "Epoch 22 Batch 60: Train Loss = 0.1221\n",
      "Epoch 22 Batch 80: Train Loss = 0.2047\n",
      "Epoch 22 Batch 100: Train Loss = 0.0723\n",
      "Epoch 22 Batch 120: Train Loss = 0.1377\n",
      "Epoch 22: Loss = 0.1329 Valid loss = 0.1294 roc = 0.9360\n",
      "confusion matrix:\n",
      "[[3851   67]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9545669555664062\n",
      "precision class 0 = 0.9685613512992859\n",
      "precision class 1 = 0.7319999933242798\n",
      "recall class 0 = 0.9828994274139404\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.9360228847212002\n",
      "AUC of PRC = 0.7287248955860348\n",
      "min(+P, Se) = 0.6753246753246753\n",
      "f1_score = 0.6559139486926854\n",
      "Epoch 23 Batch 0: Train Loss = 0.1344\n",
      "Epoch 23 Batch 20: Train Loss = 0.1554\n",
      "Epoch 23 Batch 40: Train Loss = 0.1492\n",
      "Epoch 23 Batch 60: Train Loss = 0.0684\n",
      "Epoch 23 Batch 80: Train Loss = 0.1392\n",
      "Epoch 23 Batch 100: Train Loss = 0.1083\n",
      "Epoch 23 Batch 120: Train Loss = 0.2034\n",
      "Epoch 23: Loss = 0.1338 Valid loss = 0.1268 roc = 0.9415\n",
      "confusion matrix:\n",
      "[[3849   69]\n",
      " [ 106  202]]\n",
      "accuracy = 0.9585896730422974\n",
      "precision class 0 = 0.9731984734535217\n",
      "precision class 1 = 0.7453874349594116\n",
      "recall class 0 = 0.982388973236084\n",
      "recall class 1 = 0.6558441519737244\n",
      "AUC of ROC = 0.941463143798519\n",
      "AUC of PRC = 0.742196468366005\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6977547687709453\n",
      "------------ Save best model - AUROC: 0.9415 ------------\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 0: Train Loss = 0.1020\n",
      "Epoch 24 Batch 20: Train Loss = 0.1352\n",
      "Epoch 24 Batch 40: Train Loss = 0.1414\n",
      "Epoch 24 Batch 60: Train Loss = 0.1467\n",
      "Epoch 24 Batch 80: Train Loss = 0.1591\n",
      "Epoch 24 Batch 100: Train Loss = 0.1122\n",
      "Epoch 24 Batch 120: Train Loss = 0.1063\n",
      "Epoch 24: Loss = 0.1300 Valid loss = 0.1240 roc = 0.9410\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9583530426025391\n",
      "precision class 0 = 0.9677500128746033\n",
      "precision class 1 = 0.7920354008674622\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9409916270559456\n",
      "AUC of PRC = 0.7490743293077754\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6704119854484814\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 25 Batch 0: Train Loss = 0.0919\n",
      "Epoch 25 Batch 20: Train Loss = 0.1070\n",
      "Epoch 25 Batch 40: Train Loss = 0.1508\n",
      "Epoch 25 Batch 60: Train Loss = 0.0695\n",
      "Epoch 25 Batch 80: Train Loss = 0.1293\n",
      "Epoch 25 Batch 100: Train Loss = 0.1106\n",
      "Epoch 25 Batch 120: Train Loss = 0.0978\n",
      "Epoch 25: Loss = 0.1324 Valid loss = 0.1286 roc = 0.9403\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9680319428443909\n",
      "precision class 1 = 0.8108108043670654\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9402681927567073\n",
      "AUC of PRC = 0.7383319857068213\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.679245260889821\n",
      "Epoch 26 Batch 0: Train Loss = 0.1710\n",
      "Epoch 26 Batch 20: Train Loss = 0.0952\n",
      "Epoch 26 Batch 40: Train Loss = 0.1185\n",
      "Epoch 26 Batch 60: Train Loss = 0.1219\n",
      "Epoch 26 Batch 80: Train Loss = 0.0828\n",
      "Epoch 26 Batch 100: Train Loss = 0.0930\n",
      "Epoch 26 Batch 120: Train Loss = 0.1371\n",
      "Epoch 26: Loss = 0.1300 Valid loss = 0.1287 roc = 0.9402\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 140  168]]\n",
      "accuracy = 0.9585896730422974\n",
      "precision class 0 = 0.9652001261711121\n",
      "precision class 1 = 0.8275862336158752\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.5454545617103577\n",
      "AUC of ROC = 0.9401803530823439\n",
      "AUC of PRC = 0.7341633856965961\n",
      "min(+P, Se) = 0.6623376623376623\n",
      "f1_score = 0.6575342668201176\n",
      "Epoch 27 Batch 0: Train Loss = 0.0777\n",
      "Epoch 27 Batch 20: Train Loss = 0.1109\n",
      "Epoch 27 Batch 40: Train Loss = 0.1764\n",
      "Epoch 27 Batch 60: Train Loss = 0.0824\n",
      "Epoch 27 Batch 80: Train Loss = 0.0983\n",
      "Epoch 27 Batch 100: Train Loss = 0.1978\n",
      "Epoch 27 Batch 120: Train Loss = 0.1589\n",
      "Epoch 27: Loss = 0.1306 Valid loss = 0.1244 roc = 0.9421\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.967548668384552\n",
      "precision class 1 = 0.8090909123420715\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.9420912803378346\n",
      "AUC of PRC = 0.7453719291280643\n",
      "min(+P, Se) = 0.6828478964401294\n",
      "f1_score = 0.6742424733108956\n",
      "------------ Save best model - AUROC: 0.9421 ------------\n",
      "Epoch 28 Batch 0: Train Loss = 0.1794\n",
      "Epoch 28 Batch 20: Train Loss = 0.1284\n",
      "Epoch 28 Batch 40: Train Loss = 0.0845\n",
      "Epoch 28 Batch 60: Train Loss = 0.1066\n",
      "Epoch 28 Batch 80: Train Loss = 0.0974\n",
      "Epoch 28 Batch 100: Train Loss = 0.1505\n",
      "Epoch 28 Batch 120: Train Loss = 0.0864\n",
      "Epoch 28: Loss = 0.1292 Valid loss = 0.1234 roc = 0.9416\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.968500018119812\n",
      "precision class 1 = 0.8053097128868103\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9416388231472458\n",
      "AUC of PRC = 0.7404758186363388\n",
      "min(+P, Se) = 0.672077922077922\n",
      "f1_score = 0.6816479143013258\n",
      "Epoch 29 Batch 0: Train Loss = 0.0806\n",
      "Epoch 29 Batch 20: Train Loss = 0.1039\n",
      "Epoch 29 Batch 40: Train Loss = 0.1154\n",
      "Epoch 29 Batch 60: Train Loss = 0.1291\n",
      "Epoch 29 Batch 80: Train Loss = 0.1902\n",
      "Epoch 29 Batch 100: Train Loss = 0.1298\n",
      "Epoch 29 Batch 120: Train Loss = 0.0741\n",
      "Epoch 29: Loss = 0.1259 Valid loss = 0.1254 roc = 0.9418\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 113  195]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9715866446495056\n",
      "precision class 1 = 0.7831325531005859\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.9417656106017516\n",
      "AUC of PRC = 0.7497766242778231\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.7001795238182712\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "Epoch 30 Batch 0: Train Loss = 0.1283\n",
      "Epoch 30 Batch 20: Train Loss = 0.1457\n",
      "Epoch 30 Batch 40: Train Loss = 0.0967\n",
      "Epoch 30 Batch 60: Train Loss = 0.1457\n",
      "Epoch 30 Batch 80: Train Loss = 0.1048\n",
      "Epoch 30 Batch 100: Train Loss = 0.1544\n",
      "Epoch 30 Batch 120: Train Loss = 0.1343\n",
      "Epoch 30: Loss = 0.1290 Valid loss = 0.1215 roc = 0.9424\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9680159687995911\n",
      "precision class 1 = 0.8035714030265808\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9423912611125476\n",
      "AUC of PRC = 0.7535339829213998\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6766917296063548\n",
      "------------ Save best model - AUROC: 0.9424 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 31 Batch 0: Train Loss = 0.1135\n",
      "Epoch 31 Batch 20: Train Loss = 0.1412\n",
      "Epoch 31 Batch 40: Train Loss = 0.1083\n",
      "Epoch 31 Batch 60: Train Loss = 0.1278\n",
      "Epoch 31 Batch 80: Train Loss = 0.1171\n",
      "Epoch 31 Batch 100: Train Loss = 0.1471\n",
      "Epoch 31 Batch 120: Train Loss = 0.2379\n",
      "Epoch 31: Loss = 0.1314 Valid loss = 0.1376 roc = 0.9302\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 148  160]]\n",
      "accuracy = 0.9576431512832642\n",
      "precision class 0 = 0.9633209705352783\n",
      "precision class 1 = 0.8376963138580322\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5194805264472961\n",
      "AUC of ROC = 0.9302055779850573\n",
      "AUC of PRC = 0.7258347361177329\n",
      "min(+P, Se) = 0.6623376623376623\n",
      "f1_score = 0.6412825923845556\n",
      "Epoch 32 Batch 0: Train Loss = 0.1269\n",
      "Epoch 32 Batch 20: Train Loss = 0.1702\n",
      "Epoch 32 Batch 40: Train Loss = 0.1736\n",
      "Epoch 32 Batch 60: Train Loss = 0.1089\n",
      "Epoch 32 Batch 80: Train Loss = 0.1077\n",
      "Epoch 32 Batch 100: Train Loss = 0.1203\n",
      "Epoch 32 Batch 120: Train Loss = 0.1753\n",
      "Epoch 32: Loss = 0.1328 Valid loss = 0.1280 roc = 0.9345\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 139  169]]\n",
      "accuracy = 0.9588263034820557\n",
      "precision class 0 = 0.9654400944709778\n",
      "precision class 1 = 0.8284313678741455\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.548701286315918\n",
      "AUC of ROC = 0.934528781580849\n",
      "AUC of PRC = 0.7311274198298846\n",
      "min(+P, Se) = 0.6655948553054662\n",
      "f1_score = 0.6601562395517249\n",
      "Epoch 33 Batch 0: Train Loss = 0.1375\n",
      "Epoch 33 Batch 20: Train Loss = 0.0809\n",
      "Epoch 33 Batch 40: Train Loss = 0.0923\n",
      "Epoch 33 Batch 60: Train Loss = 0.1165\n",
      "Epoch 33 Batch 80: Train Loss = 0.1907\n",
      "Epoch 33 Batch 100: Train Loss = 0.1802\n",
      "Epoch 33 Batch 120: Train Loss = 0.1275\n",
      "Epoch 33: Loss = 0.1325 Valid loss = 0.1242 roc = 0.9368\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9588263034820557\n",
      "precision class 0 = 0.9677661061286926\n",
      "precision class 1 = 0.7991071343421936\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9367628925439033\n",
      "AUC of PRC = 0.7490246608738785\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6729323272890001\n",
      "Epoch 34 Batch 0: Train Loss = 0.1011\n",
      "Epoch 34 Batch 20: Train Loss = 0.1206\n",
      "Epoch 34 Batch 40: Train Loss = 0.0857\n",
      "Epoch 34 Batch 60: Train Loss = 0.1123\n",
      "Epoch 34 Batch 80: Train Loss = 0.1395\n",
      "Epoch 34 Batch 100: Train Loss = 0.1544\n",
      "Epoch 34 Batch 120: Train Loss = 0.1113\n",
      "Epoch 34: Loss = 0.1271 Valid loss = 0.1249 roc = 0.9411\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9585896730422974\n",
      "precision class 0 = 0.9684605598449707\n",
      "precision class 1 = 0.7878788113594055\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9411018409869865\n",
      "AUC of PRC = 0.7466700484278564\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6753246662568063\n",
      "Epoch 35 Batch 0: Train Loss = 0.1003\n",
      "Epoch 35 Batch 20: Train Loss = 0.1783\n",
      "Epoch 35 Batch 40: Train Loss = 0.1096\n",
      "Epoch 35 Batch 60: Train Loss = 0.1381\n",
      "Epoch 35 Batch 80: Train Loss = 0.1922\n",
      "Epoch 35 Batch 100: Train Loss = 0.1545\n",
      "Epoch 35 Batch 120: Train Loss = 0.0767\n",
      "Epoch 35: Loss = 0.1241 Valid loss = 0.1269 roc = 0.9400\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.969477117061615\n",
      "precision class 1 = 0.8122270703315735\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9400113031430031\n",
      "AUC of PRC = 0.7381497322036541\n",
      "min(+P, Se) = 0.672077922077922\n",
      "f1_score = 0.6927374139779469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 0: Train Loss = 0.1197\n",
      "Epoch 36 Batch 20: Train Loss = 0.1101\n",
      "Epoch 36 Batch 40: Train Loss = 0.1320\n",
      "Epoch 36 Batch 60: Train Loss = 0.1394\n",
      "Epoch 36 Batch 80: Train Loss = 0.1026\n",
      "Epoch 36 Batch 100: Train Loss = 0.1693\n",
      "Epoch 36 Batch 120: Train Loss = 0.1470\n",
      "Epoch 36: Loss = 0.1275 Valid loss = 0.1266 roc = 0.9405\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9678464531898499\n",
      "precision class 1 = 0.836448609828949\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9404770191523638\n",
      "AUC of PRC = 0.7470789100179568\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.685823758182452\n",
      "Epoch 37 Batch 0: Train Loss = 0.0976\n",
      "Epoch 37 Batch 20: Train Loss = 0.1359\n",
      "Epoch 37 Batch 40: Train Loss = 0.1026\n",
      "Epoch 37 Batch 60: Train Loss = 0.1206\n",
      "Epoch 37 Batch 80: Train Loss = 0.1025\n",
      "Epoch 37 Batch 100: Train Loss = 0.0791\n",
      "Epoch 37 Batch 120: Train Loss = 0.1115\n",
      "Epoch 37: Loss = 0.1246 Valid loss = 0.1250 roc = 0.9421\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9581164121627808\n",
      "precision class 0 = 0.9675081372261047\n",
      "precision class 1 = 0.7911111116409302\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.9421310567941502\n",
      "AUC of PRC = 0.74947313988058\n",
      "min(+P, Se) = 0.6785714285714286\n",
      "f1_score = 0.6679174672050466\n",
      "Epoch 38 Batch 0: Train Loss = 0.1133\n",
      "Epoch 38 Batch 20: Train Loss = 0.1303\n",
      "Epoch 38 Batch 40: Train Loss = 0.0974\n",
      "Epoch 38 Batch 60: Train Loss = 0.1069\n",
      "Epoch 38 Batch 80: Train Loss = 0.2116\n",
      "Epoch 38 Batch 100: Train Loss = 0.0624\n",
      "Epoch 38 Batch 120: Train Loss = 0.1513\n",
      "Epoch 38: Loss = 0.1240 Valid loss = 0.1222 roc = 0.9443\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9689689874649048\n",
      "precision class 1 = 0.800000011920929\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9442947302824791\n",
      "AUC of PRC = 0.7573165841828029\n",
      "min(+P, Se) = 0.7022653721682848\n",
      "f1_score = 0.6840148871847869\n",
      "------------ Save best model - AUROC: 0.9443 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 39 Batch 0: Train Loss = 0.1463\n",
      "Epoch 39 Batch 20: Train Loss = 0.1344\n",
      "Epoch 39 Batch 40: Train Loss = 0.0947\n",
      "Epoch 39 Batch 60: Train Loss = 0.1163\n",
      "Epoch 39 Batch 80: Train Loss = 0.1711\n",
      "Epoch 39 Batch 100: Train Loss = 0.1443\n",
      "Epoch 39 Batch 120: Train Loss = 0.1654\n",
      "Epoch 39: Loss = 0.1216 Valid loss = 0.1253 roc = 0.9436\n",
      "confusion matrix:\n",
      "[[3863   55]\n",
      " [ 110  198]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9723131060600281\n",
      "precision class 1 = 0.782608687877655\n",
      "recall class 0 = 0.9859622120857239\n",
      "recall class 1 = 0.6428571343421936\n",
      "AUC of ROC = 0.9436247455964148\n",
      "AUC of PRC = 0.7520528925907617\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.7058823446455665\n",
      "Epoch 40 Batch 0: Train Loss = 0.0885\n",
      "Epoch 40 Batch 20: Train Loss = 0.1050\n",
      "Epoch 40 Batch 40: Train Loss = 0.1253\n",
      "Epoch 40 Batch 60: Train Loss = 0.1079\n",
      "Epoch 40 Batch 80: Train Loss = 0.1951\n",
      "Epoch 40 Batch 100: Train Loss = 0.1579\n",
      "Epoch 40 Batch 120: Train Loss = 0.1803\n",
      "Epoch 40: Loss = 0.1225 Valid loss = 0.1188 roc = 0.9479\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9694847464561462\n",
      "precision class 1 = 0.8157894611358643\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9479160451595368\n",
      "AUC of PRC = 0.7538247101212998\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6940298022419777\n",
      "------------ Save best model - AUROC: 0.9479 ------------\n",
      "Epoch 41 Batch 0: Train Loss = 0.1129\n",
      "Epoch 41 Batch 20: Train Loss = 0.0613\n",
      "Epoch 41 Batch 40: Train Loss = 0.1433\n",
      "Epoch 41 Batch 60: Train Loss = 0.0614\n",
      "Epoch 41 Batch 80: Train Loss = 0.0827\n",
      "Epoch 41 Batch 100: Train Loss = 0.0722\n",
      "Epoch 41 Batch 120: Train Loss = 0.0673\n",
      "Epoch 41: Loss = 0.1208 Valid loss = 0.1236 roc = 0.9436\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9676133394241333\n",
      "precision class 1 = 0.8396226167678833\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.9435828974496663\n",
      "AUC of PRC = 0.7554040450877121\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6846153959437931\n",
      "Epoch 42 Batch 0: Train Loss = 0.1303\n",
      "Epoch 42 Batch 20: Train Loss = 0.1330\n",
      "Epoch 42 Batch 40: Train Loss = 0.0927\n",
      "Epoch 42 Batch 60: Train Loss = 0.1424\n",
      "Epoch 42 Batch 80: Train Loss = 0.0807\n",
      "Epoch 42 Batch 100: Train Loss = 0.0694\n",
      "Epoch 42 Batch 120: Train Loss = 0.0745\n",
      "Epoch 42: Loss = 0.1216 Valid loss = 0.1229 roc = 0.9423\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9680798053741455\n",
      "precision class 1 = 0.8333333134651184\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9423332537804208\n",
      "AUC of PRC = 0.7530261147450644\n",
      "min(+P, Se) = 0.6688102893890675\n",
      "f1_score = 0.6870228448021668\n",
      "Epoch 43 Batch 0: Train Loss = 0.1061\n",
      "Epoch 43 Batch 20: Train Loss = 0.1256\n",
      "Epoch 43 Batch 40: Train Loss = 0.1763\n",
      "Epoch 43 Batch 60: Train Loss = 0.1457\n",
      "Epoch 43 Batch 80: Train Loss = 0.1278\n",
      "Epoch 43 Batch 100: Train Loss = 0.1605\n",
      "Epoch 43 Batch 120: Train Loss = 0.1079\n",
      "Epoch 43: Loss = 0.1212 Valid loss = 0.1325 roc = 0.9422\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 141  167]]\n",
      "accuracy = 0.9576431512832642\n",
      "precision class 0 = 0.9649341106414795\n",
      "precision class 1 = 0.8146341443061829\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5422077775001526\n",
      "AUC of ROC = 0.9422230398493798\n",
      "AUC of PRC = 0.7417106938642056\n",
      "min(+P, Se) = 0.6838709677419355\n",
      "f1_score = 0.6510721135030478\n",
      "Epoch 44 Batch 0: Train Loss = 0.1600\n",
      "Epoch 44 Batch 20: Train Loss = 0.1784\n",
      "Epoch 44 Batch 40: Train Loss = 0.0742\n",
      "Epoch 44 Batch 60: Train Loss = 0.0740\n",
      "Epoch 44 Batch 80: Train Loss = 0.1288\n",
      "Epoch 44 Batch 100: Train Loss = 0.1061\n",
      "Epoch 44 Batch 120: Train Loss = 0.0941\n",
      "Epoch 44: Loss = 0.1221 Valid loss = 0.1279 roc = 0.9444\n",
      "confusion matrix:\n",
      "[[3890   28]\n",
      " [ 143  165]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9645425081253052\n",
      "precision class 1 = 0.8549222946166992\n",
      "recall class 0 = 0.9928535223007202\n",
      "recall class 1 = 0.5357142686843872\n",
      "AUC of ROC = 0.9444372625842765\n",
      "AUC of PRC = 0.7556967544900896\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6586826262576889\n",
      "Epoch 45 Batch 0: Train Loss = 0.1646\n",
      "Epoch 45 Batch 20: Train Loss = 0.1115\n",
      "Epoch 45 Batch 40: Train Loss = 0.1400\n",
      "Epoch 45 Batch 60: Train Loss = 0.1260\n",
      "Epoch 45 Batch 80: Train Loss = 0.1205\n",
      "Epoch 45 Batch 100: Train Loss = 0.0918\n",
      "Epoch 45 Batch 120: Train Loss = 0.1388\n",
      "Epoch 45: Loss = 0.1198 Valid loss = 0.1208 roc = 0.9463\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9704630970954895\n",
      "precision class 1 = 0.822510838508606\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9462794097173883\n",
      "AUC of PRC = 0.7645807476755925\n",
      "min(+P, Se) = 0.7032258064516129\n",
      "f1_score = 0.7050092414933818\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 46 Batch 0: Train Loss = 0.1139\n",
      "Epoch 46 Batch 20: Train Loss = 0.1083\n",
      "Epoch 46 Batch 40: Train Loss = 0.1397\n",
      "Epoch 46 Batch 60: Train Loss = 0.2006\n",
      "Epoch 46 Batch 80: Train Loss = 0.1075\n",
      "Epoch 46 Batch 100: Train Loss = 0.1259\n",
      "Epoch 46 Batch 120: Train Loss = 0.1307\n",
      "Epoch 46: Loss = 0.1196 Valid loss = 0.1260 roc = 0.9420\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 136  172]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9661691784858704\n",
      "precision class 1 = 0.8349514603614807\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5584415793418884\n",
      "AUC of ROC = 0.9419943252255656\n",
      "AUC of PRC = 0.7479897156431976\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6692607166996373\n",
      "Epoch 47 Batch 0: Train Loss = 0.1070\n",
      "Epoch 47 Batch 20: Train Loss = 0.0808\n",
      "Epoch 47 Batch 40: Train Loss = 0.1150\n",
      "Epoch 47 Batch 60: Train Loss = 0.1127\n",
      "Epoch 47 Batch 80: Train Loss = 0.1167\n",
      "Epoch 47 Batch 100: Train Loss = 0.0712\n",
      "Epoch 47 Batch 120: Train Loss = 0.0894\n",
      "Epoch 47: Loss = 0.1192 Valid loss = 0.1231 roc = 0.9451\n",
      "confusion matrix:\n",
      "[[3856   62]\n",
      " [ 111  197]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9720191359519958\n",
      "precision class 1 = 0.760617733001709\n",
      "recall class 0 = 0.9841756224632263\n",
      "recall class 1 = 0.6396104097366333\n",
      "AUC of ROC = 0.9451416373315302\n",
      "AUC of PRC = 0.7519837746806224\n",
      "min(+P, Se) = 0.6935483870967742\n",
      "f1_score = 0.6948853619050325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 0: Train Loss = 0.0895\n",
      "Epoch 48 Batch 20: Train Loss = 0.1149\n",
      "Epoch 48 Batch 40: Train Loss = 0.1267\n",
      "Epoch 48 Batch 60: Train Loss = 0.1415\n",
      "Epoch 48 Batch 80: Train Loss = 0.0691\n",
      "Epoch 48 Batch 100: Train Loss = 0.1316\n",
      "Epoch 48 Batch 120: Train Loss = 0.1231\n",
      "Epoch 48: Loss = 0.1154 Valid loss = 0.1275 roc = 0.9447\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9699398875236511\n",
      "precision class 1 = 0.8034188151359558\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.944736414682816\n",
      "AUC of PRC = 0.7565141390956854\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.693726957885612\n",
      "Epoch 49 Batch 0: Train Loss = 0.1364\n",
      "Epoch 49 Batch 20: Train Loss = 0.1313\n",
      "Epoch 49 Batch 40: Train Loss = 0.1176\n",
      "Epoch 49 Batch 60: Train Loss = 0.1317\n",
      "Epoch 49 Batch 80: Train Loss = 0.1167\n",
      "Epoch 49 Batch 100: Train Loss = 0.0929\n",
      "Epoch 49 Batch 120: Train Loss = 0.1157\n",
      "Epoch 49: Loss = 0.1160 Valid loss = 0.1226 roc = 0.9445\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9678223729133606\n",
      "precision class 1 = 0.8248847723007202\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9445441618106243\n",
      "AUC of PRC = 0.7562364394815422\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6819047833336737\n",
      "Epoch 50 Batch 0: Train Loss = 0.1298\n",
      "Epoch 50 Batch 20: Train Loss = 0.1224\n",
      "Epoch 50 Batch 40: Train Loss = 0.0842\n",
      "Epoch 50 Batch 60: Train Loss = 0.0666\n",
      "Epoch 50 Batch 80: Train Loss = 0.1594\n",
      "Epoch 50 Batch 100: Train Loss = 0.1027\n",
      "Epoch 50 Batch 120: Train Loss = 0.1206\n",
      "Epoch 50: Loss = 0.1152 Valid loss = 0.1322 roc = 0.9451\n",
      "confusion matrix:\n",
      "[[3891   27]\n",
      " [ 140  168]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.965269148349762\n",
      "precision class 1 = 0.8615384697914124\n",
      "recall class 0 = 0.9931087493896484\n",
      "recall class 1 = 0.5454545617103577\n",
      "AUC of ROC = 0.9450927454373089\n",
      "AUC of PRC = 0.7626109572405517\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6679920623844197\n",
      "Epoch 51 Batch 0: Train Loss = 0.1315\n",
      "Epoch 51 Batch 20: Train Loss = 0.1472\n",
      "Epoch 51 Batch 40: Train Loss = 0.1355\n",
      "Epoch 51 Batch 60: Train Loss = 0.1331\n",
      "Epoch 51 Batch 80: Train Loss = 0.1216\n",
      "Epoch 51 Batch 100: Train Loss = 0.1212\n",
      "Epoch 51 Batch 120: Train Loss = 0.1462\n",
      "Epoch 51: Loss = 0.1163 Valid loss = 0.1265 roc = 0.9421\n",
      "confusion matrix:\n",
      "[[3885   33]\n",
      " [ 139  169]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9654572606086731\n",
      "precision class 1 = 0.8366336822509766\n",
      "recall class 0 = 0.9915773272514343\n",
      "recall class 1 = 0.548701286315918\n",
      "AUC of ROC = 0.942092109014008\n",
      "AUC of PRC = 0.7501675292443932\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6627450949299658\n",
      "Epoch 52 Batch 0: Train Loss = 0.1147\n",
      "Epoch 52 Batch 20: Train Loss = 0.1624\n",
      "Epoch 52 Batch 40: Train Loss = 0.1062\n",
      "Epoch 52 Batch 60: Train Loss = 0.1250\n",
      "Epoch 52 Batch 80: Train Loss = 0.1465\n",
      "Epoch 52 Batch 100: Train Loss = 0.1104\n",
      "Epoch 52 Batch 120: Train Loss = 0.1488\n",
      "Epoch 52: Loss = 0.1143 Valid loss = 0.1230 roc = 0.9457\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9710982441902161\n",
      "precision class 1 = 0.7813765406608582\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9457142525672388\n",
      "AUC of PRC = 0.7577714201688492\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6954954844792077\n",
      "Epoch 53 Batch 0: Train Loss = 0.1750\n",
      "Epoch 53 Batch 20: Train Loss = 0.1120\n",
      "Epoch 53 Batch 40: Train Loss = 0.1425\n",
      "Epoch 53 Batch 60: Train Loss = 0.1315\n",
      "Epoch 53 Batch 80: Train Loss = 0.1095\n",
      "Epoch 53 Batch 100: Train Loss = 0.0820\n",
      "Epoch 53 Batch 120: Train Loss = 0.0931\n",
      "Epoch 53: Loss = 0.1168 Valid loss = 0.1240 roc = 0.9435\n",
      "confusion matrix:\n",
      "[[3888   30]\n",
      " [ 135  173]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9664429426193237\n",
      "precision class 1 = 0.8522167205810547\n",
      "recall class 0 = 0.992343008518219\n",
      "recall class 1 = 0.5616883039474487\n",
      "AUC of ROC = 0.9435489217265633\n",
      "AUC of PRC = 0.7588279938226308\n",
      "min(+P, Se) = 0.6957928802588996\n",
      "f1_score = 0.6771037036783365\n",
      "Epoch 54 Batch 0: Train Loss = 0.1362\n",
      "Epoch 54 Batch 20: Train Loss = 0.0869\n",
      "Epoch 54 Batch 40: Train Loss = 0.1406\n",
      "Epoch 54 Batch 60: Train Loss = 0.0958\n",
      "Epoch 54 Batch 80: Train Loss = 0.1158\n",
      "Epoch 54 Batch 100: Train Loss = 0.1558\n",
      "Epoch 54 Batch 120: Train Loss = 0.1139\n",
      "Epoch 54: Loss = 0.1160 Valid loss = 0.1283 roc = 0.9421\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9668906927108765\n",
      "precision class 1 = 0.8373205661773682\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9420672487288106\n",
      "AUC of PRC = 0.7522034554907637\n",
      "min(+P, Se) = 0.6828478964401294\n",
      "f1_score = 0.6769826141295266\n",
      "Epoch 55 Batch 0: Train Loss = 0.0701\n",
      "Epoch 55 Batch 20: Train Loss = 0.0934\n",
      "Epoch 55 Batch 40: Train Loss = 0.0696\n",
      "Epoch 55 Batch 60: Train Loss = 0.1007\n",
      "Epoch 55 Batch 80: Train Loss = 0.1181\n",
      "Epoch 55 Batch 100: Train Loss = 0.1633\n",
      "Epoch 55 Batch 120: Train Loss = 0.0880\n",
      "Epoch 55: Loss = 0.1154 Valid loss = 0.1242 roc = 0.9445\n",
      "confusion matrix:\n",
      "[[3881   37]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9678304195404053\n",
      "precision class 1 = 0.8287037014961243\n",
      "recall class 0 = 0.9905564188957214\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9445242735824666\n",
      "AUC of PRC = 0.762006901039863\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6832061055851222\n",
      "Epoch 56 Batch 0: Train Loss = 0.1011\n",
      "Epoch 56 Batch 20: Train Loss = 0.1057\n",
      "Epoch 56 Batch 40: Train Loss = 0.0889\n",
      "Epoch 56 Batch 60: Train Loss = 0.0886\n",
      "Epoch 56 Batch 80: Train Loss = 0.2330\n",
      "Epoch 56 Batch 100: Train Loss = 0.1074\n",
      "Epoch 56 Batch 120: Train Loss = 0.0891\n",
      "Epoch 56: Loss = 0.1150 Valid loss = 0.1224 roc = 0.9489\n",
      "confusion matrix:\n",
      "[[3888   30]\n",
      " [ 132  176]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.967164158821106\n",
      "precision class 1 = 0.8543689250946045\n",
      "recall class 0 = 0.992343008518219\n",
      "recall class 1 = 0.5714285969734192\n",
      "AUC of ROC = 0.9488516205591243\n",
      "AUC of PRC = 0.7718730566623295\n",
      "min(+P, Se) = 0.7184466019417476\n",
      "f1_score = 0.6848249474662501\n",
      "------------ Save best model - AUROC: 0.9489 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 57 Batch 0: Train Loss = 0.0784\n",
      "Epoch 57 Batch 20: Train Loss = 0.0886\n",
      "Epoch 57 Batch 40: Train Loss = 0.1003\n",
      "Epoch 57 Batch 60: Train Loss = 0.1278\n",
      "Epoch 57 Batch 80: Train Loss = 0.1502\n",
      "Epoch 57 Batch 100: Train Loss = 0.1143\n",
      "Epoch 57 Batch 120: Train Loss = 0.1238\n",
      "Epoch 57: Loss = 0.1153 Valid loss = 0.1191 roc = 0.9482\n",
      "confusion matrix:\n",
      "[[3886   32]\n",
      " [ 131  177]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9673885703086853\n",
      "precision class 1 = 0.8468899726867676\n",
      "recall class 0 = 0.9918325543403625\n",
      "recall class 1 = 0.5746753215789795\n",
      "AUC of ROC = 0.9482317707815412\n",
      "AUC of PRC = 0.7667975432751873\n",
      "min(+P, Se) = 0.7087378640776699\n",
      "f1_score = 0.6847195402968247\n",
      "Epoch 58 Batch 0: Train Loss = 0.1314\n",
      "Epoch 58 Batch 20: Train Loss = 0.1211\n",
      "Epoch 58 Batch 40: Train Loss = 0.1353\n",
      "Epoch 58 Batch 60: Train Loss = 0.1216\n",
      "Epoch 58 Batch 80: Train Loss = 0.0891\n",
      "Epoch 58 Batch 100: Train Loss = 0.0692\n",
      "Epoch 58 Batch 120: Train Loss = 0.1453\n",
      "Epoch 58: Loss = 0.1115 Valid loss = 0.1160 roc = 0.9485\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9711562395095825\n",
      "precision class 1 = 0.8075313568115234\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9484654574623947\n",
      "AUC of PRC = 0.7761487332912628\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.7056672767268992\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "Epoch 59 Batch 0: Train Loss = 0.0786\n",
      "Epoch 59 Batch 20: Train Loss = 0.1615\n",
      "Epoch 59 Batch 40: Train Loss = 0.0862\n",
      "Epoch 59 Batch 60: Train Loss = 0.0590\n",
      "Epoch 59 Batch 80: Train Loss = 0.1388\n",
      "Epoch 59 Batch 100: Train Loss = 0.0723\n",
      "Epoch 59 Batch 120: Train Loss = 0.0948\n",
      "Epoch 59: Loss = 0.1118 Valid loss = 0.1255 roc = 0.9467\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9694847464561462\n",
      "precision class 1 = 0.8157894611358643\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9466871183946223\n",
      "AUC of PRC = 0.7596092799958617\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6940298022419777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 0: Train Loss = 0.0914\n",
      "Epoch 60 Batch 20: Train Loss = 0.0997\n",
      "Epoch 60 Batch 40: Train Loss = 0.0474\n",
      "Epoch 60 Batch 60: Train Loss = 0.0913\n",
      "Epoch 60 Batch 80: Train Loss = 0.1215\n",
      "Epoch 60 Batch 100: Train Loss = 0.0753\n",
      "Epoch 60 Batch 120: Train Loss = 0.0864\n",
      "Epoch 60: Loss = 0.1131 Valid loss = 0.1223 roc = 0.9446\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9706840515136719\n",
      "precision class 1 = 0.8127659559249878\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9446245433994285\n",
      "AUC of PRC = 0.7586205579956893\n",
      "min(+P, Se) = 0.7142857142857143\n",
      "f1_score = 0.7034990578237206\n",
      "Epoch 61 Batch 0: Train Loss = 0.0900\n",
      "Epoch 61 Batch 20: Train Loss = 0.1038\n",
      "Epoch 61 Batch 40: Train Loss = 0.1429\n",
      "Epoch 61 Batch 60: Train Loss = 0.1203\n",
      "Epoch 61 Batch 80: Train Loss = 0.1174\n",
      "Epoch 61 Batch 100: Train Loss = 0.1067\n",
      "Epoch 61 Batch 120: Train Loss = 0.1476\n",
      "Epoch 61: Loss = 0.1158 Valid loss = 0.1264 roc = 0.9403\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 131  177]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9673967361450195\n",
      "precision class 1 = 0.8509615659713745\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5746753215789795\n",
      "AUC of ROC = 0.9402731648137468\n",
      "AUC of PRC = 0.7535606265496866\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6860465183616807\n",
      "Epoch 62 Batch 0: Train Loss = 0.0838\n",
      "Epoch 62 Batch 20: Train Loss = 0.1147\n",
      "Epoch 62 Batch 40: Train Loss = 0.1182\n",
      "Epoch 62 Batch 60: Train Loss = 0.1277\n",
      "Epoch 62 Batch 80: Train Loss = 0.0946\n",
      "Epoch 62 Batch 100: Train Loss = 0.1330\n",
      "Epoch 62 Batch 120: Train Loss = 0.1512\n",
      "Epoch 62: Loss = 0.1152 Valid loss = 0.1204 roc = 0.9463\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 117  191]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9706693291664124\n",
      "precision class 1 = 0.8059071898460388\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9463332736686488\n",
      "AUC of PRC = 0.7613352471447755\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.7009174459713615\n",
      "Epoch 63 Batch 0: Train Loss = 0.1027\n",
      "Epoch 63 Batch 20: Train Loss = 0.1018\n",
      "Epoch 63 Batch 40: Train Loss = 0.1282\n",
      "Epoch 63 Batch 60: Train Loss = 0.0855\n",
      "Epoch 63 Batch 80: Train Loss = 0.0895\n",
      "Epoch 63 Batch 100: Train Loss = 0.1347\n",
      "Epoch 63 Batch 120: Train Loss = 0.0939\n",
      "Epoch 63: Loss = 0.1133 Valid loss = 0.1271 roc = 0.9404\n",
      "confusion matrix:\n",
      "[[3886   32]\n",
      " [ 136  172]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.966185986995697\n",
      "precision class 1 = 0.843137264251709\n",
      "recall class 0 = 0.9918325543403625\n",
      "recall class 1 = 0.5584415793418884\n",
      "AUC of ROC = 0.9404405574007413\n",
      "AUC of PRC = 0.7474733558590733\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.671874989522622\n",
      "Epoch 64 Batch 0: Train Loss = 0.0763\n",
      "Epoch 64 Batch 20: Train Loss = 0.0938\n",
      "Epoch 64 Batch 40: Train Loss = 0.1290\n",
      "Epoch 64 Batch 60: Train Loss = 0.1132\n",
      "Epoch 64 Batch 80: Train Loss = 0.0945\n",
      "Epoch 64 Batch 100: Train Loss = 0.1369\n",
      "Epoch 64 Batch 120: Train Loss = 0.1237\n",
      "Epoch 64: Loss = 0.1112 Valid loss = 0.1282 roc = 0.9463\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 125  183]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9687890410423279\n",
      "precision class 1 = 0.8280543088912964\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.9463403174161215\n",
      "AUC of PRC = 0.7612128099264742\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6918714327818699\n",
      "Epoch 65 Batch 0: Train Loss = 0.0626\n",
      "Epoch 65 Batch 20: Train Loss = 0.1054\n",
      "Epoch 65 Batch 40: Train Loss = 0.0775\n",
      "Epoch 65 Batch 60: Train Loss = 0.0884\n",
      "Epoch 65 Batch 80: Train Loss = 0.1678\n",
      "Epoch 65 Batch 100: Train Loss = 0.0762\n",
      "Epoch 65 Batch 120: Train Loss = 0.1148\n",
      "Epoch 65: Loss = 0.1125 Valid loss = 0.1199 roc = 0.9473\n",
      "confusion matrix:\n",
      "[[3864   54]\n",
      " [ 107  201]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9730546474456787\n",
      "precision class 1 = 0.7882353067398071\n",
      "recall class 0 = 0.9862174391746521\n",
      "recall class 1 = 0.6525974273681641\n",
      "AUC of ROC = 0.9473135975815914\n",
      "AUC of PRC = 0.7634461958080279\n",
      "min(+P, Se) = 0.7\n",
      "f1_score = 0.7140319915866187\n",
      "Epoch 66 Batch 0: Train Loss = 0.1045\n",
      "Epoch 66 Batch 20: Train Loss = 0.0886\n",
      "Epoch 66 Batch 40: Train Loss = 0.0715\n",
      "Epoch 66 Batch 60: Train Loss = 0.1192\n",
      "Epoch 66 Batch 80: Train Loss = 0.0672\n",
      "Epoch 66 Batch 100: Train Loss = 0.1045\n",
      "Epoch 66 Batch 120: Train Loss = 0.1153\n",
      "Epoch 66: Loss = 0.1157 Valid loss = 0.1281 roc = 0.9367\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9687421917915344\n",
      "precision class 1 = 0.8061674237251282\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.9367256021161074\n",
      "AUC of PRC = 0.7577041170614882\n",
      "min(+P, Se) = 0.7055016181229773\n",
      "f1_score = 0.6841121603234989\n",
      "Epoch 67 Batch 0: Train Loss = 0.0999\n",
      "Epoch 67 Batch 20: Train Loss = 0.1187\n",
      "Epoch 67 Batch 40: Train Loss = 0.0847\n",
      "Epoch 67 Batch 60: Train Loss = 0.1266\n",
      "Epoch 67 Batch 80: Train Loss = 0.1666\n",
      "Epoch 67 Batch 100: Train Loss = 0.1175\n",
      "Epoch 67 Batch 120: Train Loss = 0.0584\n",
      "Epoch 67: Loss = 0.1162 Valid loss = 0.1225 roc = 0.9365\n",
      "confusion matrix:\n",
      "[[3881   37]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9626123905181885\n",
      "precision class 0 = 0.9697651267051697\n",
      "precision class 1 = 0.8348214030265808\n",
      "recall class 0 = 0.9905564188957214\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9365200904251441\n",
      "AUC of PRC = 0.7603141466939927\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.7030075154476215\n",
      "Epoch 68 Batch 0: Train Loss = 0.0947\n",
      "Epoch 68 Batch 20: Train Loss = 0.1074\n",
      "Epoch 68 Batch 40: Train Loss = 0.1203\n",
      "Epoch 68 Batch 60: Train Loss = 0.0917\n",
      "Epoch 68 Batch 80: Train Loss = 0.0990\n",
      "Epoch 68 Batch 100: Train Loss = 0.1049\n",
      "Epoch 68 Batch 120: Train Loss = 0.0902\n",
      "Epoch 68: Loss = 0.1154 Valid loss = 0.1290 roc = 0.9425\n",
      "confusion matrix:\n",
      "[[3892   26]\n",
      " [ 135  173]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9664762616157532\n",
      "precision class 1 = 0.8693467378616333\n",
      "recall class 0 = 0.9933639764785767\n",
      "recall class 1 = 0.5616883039474487\n",
      "AUC of ROC = 0.9425006463674153\n",
      "AUC of PRC = 0.7582377404338936\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6824457549473393\n",
      "Epoch 69 Batch 0: Train Loss = 0.0760\n",
      "Epoch 69 Batch 20: Train Loss = 0.1196\n",
      "Epoch 69 Batch 40: Train Loss = 0.1204\n",
      "Epoch 69 Batch 60: Train Loss = 0.1363\n",
      "Epoch 69 Batch 80: Train Loss = 0.1001\n",
      "Epoch 69 Batch 100: Train Loss = 0.1017\n",
      "Epoch 69 Batch 120: Train Loss = 0.1661\n",
      "Epoch 69: Loss = 0.1121 Valid loss = 0.1211 roc = 0.9445\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 120  188]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.969962477684021\n",
      "precision class 1 = 0.8138527870178223\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9445126721160413\n",
      "AUC of PRC = 0.7649497588222138\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6975881031581334\n",
      "Epoch 70 Batch 0: Train Loss = 0.0930\n",
      "Epoch 70 Batch 20: Train Loss = 0.1431\n",
      "Epoch 70 Batch 40: Train Loss = 0.0774\n",
      "Epoch 70 Batch 60: Train Loss = 0.1054\n",
      "Epoch 70 Batch 80: Train Loss = 0.0940\n",
      "Epoch 70 Batch 100: Train Loss = 0.1355\n",
      "Epoch 70 Batch 120: Train Loss = 0.1287\n",
      "Epoch 70: Loss = 0.1144 Valid loss = 0.1230 roc = 0.9425\n",
      "confusion matrix:\n",
      "[[3894   24]\n",
      " [ 142  166]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9648166298866272\n",
      "precision class 1 = 0.8736842274665833\n",
      "recall class 0 = 0.9938744306564331\n",
      "recall class 1 = 0.5389610528945923\n",
      "AUC of ROC = 0.9424600412349264\n",
      "AUC of PRC = 0.7658401620477712\n",
      "min(+P, Se) = 0.7142857142857143\n",
      "f1_score = 0.6666666541287446\n",
      "Epoch 71 Batch 0: Train Loss = 0.0962\n",
      "Epoch 71 Batch 20: Train Loss = 0.1372\n",
      "Epoch 71 Batch 40: Train Loss = 0.1215\n",
      "Epoch 71 Batch 60: Train Loss = 0.1483\n",
      "Epoch 71 Batch 80: Train Loss = 0.1135\n",
      "Epoch 71 Batch 100: Train Loss = 0.1518\n",
      "Epoch 71 Batch 120: Train Loss = 0.1056\n",
      "Epoch 71: Loss = 0.1094 Valid loss = 0.1285 roc = 0.9447\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 130  178]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9676052927970886\n",
      "precision class 1 = 0.8356807231903076\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.5779221057891846\n",
      "AUC of ROC = 0.9446692919127835\n",
      "AUC of PRC = 0.7651438123826889\n",
      "min(+P, Se) = 0.7032258064516129\n",
      "f1_score = 0.6833013536938497\n",
      "Epoch 72 Batch 0: Train Loss = 0.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 20: Train Loss = 0.1077\n",
      "Epoch 72 Batch 40: Train Loss = 0.1488\n",
      "Epoch 72 Batch 60: Train Loss = 0.0949\n",
      "Epoch 72 Batch 80: Train Loss = 0.1311\n",
      "Epoch 72 Batch 100: Train Loss = 0.1196\n",
      "Epoch 72 Batch 120: Train Loss = 0.1407\n",
      "Epoch 72: Loss = 0.1136 Valid loss = 0.1268 roc = 0.9470\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9687812328338623\n",
      "precision class 1 = 0.8243243098258972\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.946955609474752\n",
      "AUC of PRC = 0.7613240288593953\n",
      "min(+P, Se) = 0.7096774193548387\n",
      "f1_score = 0.6905660352625427\n",
      "Epoch 73 Batch 0: Train Loss = 0.0717\n",
      "Epoch 73 Batch 20: Train Loss = 0.1226\n",
      "Epoch 73 Batch 40: Train Loss = 0.1358\n",
      "Epoch 73 Batch 60: Train Loss = 0.1144\n",
      "Epoch 73 Batch 80: Train Loss = 0.0715\n",
      "Epoch 73 Batch 100: Train Loss = 0.0769\n",
      "Epoch 73 Batch 120: Train Loss = 0.0766\n",
      "Epoch 73: Loss = 0.1197 Valid loss = 0.1185 roc = 0.9481\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9597728252410889\n",
      "precision class 0 = 0.9677982926368713\n",
      "precision class 1 = 0.8136363625526428\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9480577487851607\n",
      "AUC of PRC = 0.7642918104153116\n",
      "min(+P, Se) = 0.7077922077922078\n",
      "f1_score = 0.6780303021272024\n",
      "Epoch 74 Batch 0: Train Loss = 0.1592\n",
      "Epoch 74 Batch 20: Train Loss = 0.1496\n",
      "Epoch 74 Batch 40: Train Loss = 0.0677\n",
      "Epoch 74 Batch 60: Train Loss = 0.1258\n",
      "Epoch 74 Batch 80: Train Loss = 0.1318\n",
      "Epoch 74 Batch 100: Train Loss = 0.1170\n",
      "Epoch 74 Batch 120: Train Loss = 0.0950\n",
      "Epoch 74: Loss = 0.1199 Valid loss = 0.1211 roc = 0.9453\n",
      "confusion matrix:\n",
      "[[3881   37]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9621391296386719\n",
      "precision class 0 = 0.9692807197570801\n",
      "precision class 1 = 0.8333333134651184\n",
      "recall class 0 = 0.9905564188957214\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9452982571282724\n",
      "AUC of PRC = 0.7628573794937694\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.698113233775761\n",
      "Epoch 75 Batch 0: Train Loss = 0.1115\n",
      "Epoch 75 Batch 20: Train Loss = 0.1953\n",
      "Epoch 75 Batch 40: Train Loss = 0.1054\n",
      "Epoch 75 Batch 60: Train Loss = 0.1209\n",
      "Epoch 75 Batch 80: Train Loss = 0.1200\n",
      "Epoch 75 Batch 100: Train Loss = 0.1029\n",
      "Epoch 75 Batch 120: Train Loss = 0.1589\n",
      "Epoch 75: Loss = 0.1150 Valid loss = 0.1199 roc = 0.9443\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 127  181]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9683212637901306\n",
      "precision class 1 = 0.8341013789176941\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.9443461082052199\n",
      "AUC of PRC = 0.771932889914904\n",
      "min(+P, Se) = 0.7152103559870551\n",
      "f1_score = 0.6895238382763346\n",
      "Epoch 76 Batch 0: Train Loss = 0.1271\n",
      "Epoch 76 Batch 20: Train Loss = 0.0733\n",
      "Epoch 76 Batch 40: Train Loss = 0.0876\n",
      "Epoch 76 Batch 60: Train Loss = 0.1051\n",
      "Epoch 76 Batch 80: Train Loss = 0.1196\n",
      "Epoch 76 Batch 100: Train Loss = 0.1375\n",
      "Epoch 76 Batch 120: Train Loss = 0.1505\n",
      "Epoch 76: Loss = 0.1110 Valid loss = 0.1303 roc = 0.9422\n",
      "confusion matrix:\n",
      "[[3885   33]\n",
      " [ 139  169]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9654572606086731\n",
      "precision class 1 = 0.8366336822509766\n",
      "recall class 0 = 0.9915773272514343\n",
      "recall class 1 = 0.548701286315918\n",
      "AUC of ROC = 0.9422246972017264\n",
      "AUC of PRC = 0.7589823447483367\n",
      "min(+P, Se) = 0.6967741935483871\n",
      "f1_score = 0.6627450949299658\n",
      "Epoch 77 Batch 0: Train Loss = 0.0974\n",
      "Epoch 77 Batch 20: Train Loss = 0.1089\n",
      "Epoch 77 Batch 40: Train Loss = 0.1660\n",
      "Epoch 77 Batch 60: Train Loss = 0.1223\n",
      "Epoch 77 Batch 80: Train Loss = 0.1191\n",
      "Epoch 77 Batch 100: Train Loss = 0.1111\n",
      "Epoch 77 Batch 120: Train Loss = 0.1138\n",
      "Epoch 77: Loss = 0.1120 Valid loss = 0.1270 roc = 0.9404\n",
      "confusion matrix:\n",
      "[[3889   29]\n",
      " [ 142  166]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9647729992866516\n",
      "precision class 1 = 0.8512820601463318\n",
      "recall class 0 = 0.9925982356071472\n",
      "recall class 1 = 0.5389610528945923\n",
      "AUC of ROC = 0.9404107250585045\n",
      "AUC of PRC = 0.7632302137592796\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.6600398028426815\n",
      "Epoch 78 Batch 0: Train Loss = 0.1177\n",
      "Epoch 78 Batch 20: Train Loss = 0.0951\n",
      "Epoch 78 Batch 40: Train Loss = 0.1044\n",
      "Epoch 78 Batch 60: Train Loss = 0.0954\n",
      "Epoch 78 Batch 80: Train Loss = 0.0970\n",
      "Epoch 78 Batch 100: Train Loss = 0.0827\n",
      "Epoch 78 Batch 120: Train Loss = 0.1112\n",
      "Epoch 78: Loss = 0.1087 Valid loss = 0.1272 roc = 0.9448\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 132  176]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.967131495475769\n",
      "precision class 1 = 0.8380952477455139\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5714285969734192\n",
      "AUC of ROC = 0.9448267403856991\n",
      "AUC of PRC = 0.7601232486707398\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6795367007711839\n",
      "Epoch 79 Batch 0: Train Loss = 0.0814\n",
      "Epoch 79 Batch 20: Train Loss = 0.1191\n",
      "Epoch 79 Batch 40: Train Loss = 0.1049\n",
      "Epoch 79 Batch 60: Train Loss = 0.1292\n",
      "Epoch 79 Batch 80: Train Loss = 0.1374\n",
      "Epoch 79 Batch 100: Train Loss = 0.1093\n",
      "Epoch 79 Batch 120: Train Loss = 0.1501\n",
      "Epoch 79: Loss = 0.1090 Valid loss = 0.1364 roc = 0.9384\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 149  159]]\n",
      "accuracy = 0.9564599990844727\n",
      "precision class 0 = 0.9630456566810608\n",
      "precision class 1 = 0.8195876479148865\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.5162337422370911\n",
      "AUC of ROC = 0.9383680382914686\n",
      "AUC of PRC = 0.7315387067878724\n",
      "min(+P, Se) = 0.6590909090909091\n",
      "f1_score = 0.6334661230814113\n",
      "Epoch 80 Batch 0: Train Loss = 0.0932\n",
      "Epoch 80 Batch 20: Train Loss = 0.1411\n",
      "Epoch 80 Batch 40: Train Loss = 0.1203\n",
      "Epoch 80 Batch 60: Train Loss = 0.1082\n",
      "Epoch 80 Batch 80: Train Loss = 0.1519\n",
      "Epoch 80 Batch 100: Train Loss = 0.1803\n",
      "Epoch 80 Batch 120: Train Loss = 0.0848\n",
      "Epoch 80: Loss = 0.1105 Valid loss = 0.1325 roc = 0.9445\n",
      "confusion matrix:\n",
      "[[3892   26]\n",
      " [ 140  168]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9652777910232544\n",
      "precision class 1 = 0.8659793734550476\n",
      "recall class 0 = 0.9933639764785767\n",
      "recall class 1 = 0.5454545617103577\n",
      "AUC of ROC = 0.9445110147636946\n",
      "AUC of PRC = 0.7587949145710517\n",
      "min(+P, Se) = 0.7022653721682848\n",
      "f1_score = 0.6693227190159323\n",
      "Epoch 81 Batch 0: Train Loss = 0.0956\n",
      "Epoch 81 Batch 20: Train Loss = 0.0588\n",
      "Epoch 81 Batch 40: Train Loss = 0.1032\n",
      "Epoch 81 Batch 60: Train Loss = 0.0841\n",
      "Epoch 81 Batch 80: Train Loss = 0.0895\n",
      "Epoch 81 Batch 100: Train Loss = 0.1500\n",
      "Epoch 81 Batch 120: Train Loss = 0.0600\n",
      "Epoch 81: Loss = 0.1095 Valid loss = 0.1343 roc = 0.9443\n",
      "confusion matrix:\n",
      "[[3894   24]\n",
      " [ 140  168]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9652950167655945\n",
      "precision class 1 = 0.875\n",
      "recall class 0 = 0.9938744306564331\n",
      "recall class 1 = 0.5454545617103577\n",
      "AUC of ROC = 0.9443469368813934\n",
      "AUC of PRC = 0.7646341478496208\n",
      "min(+P, Se) = 0.7\n",
      "f1_score = 0.6720000405349744\n",
      "Epoch 82 Batch 0: Train Loss = 0.1028\n",
      "Epoch 82 Batch 20: Train Loss = 0.1444\n",
      "Epoch 82 Batch 40: Train Loss = 0.1014\n",
      "Epoch 82 Batch 60: Train Loss = 0.1980\n",
      "Epoch 82 Batch 80: Train Loss = 0.0713\n",
      "Epoch 82 Batch 100: Train Loss = 0.1020\n",
      "Epoch 82 Batch 120: Train Loss = 0.1019\n",
      "Epoch 82: Loss = 0.1159 Valid loss = 0.1266 roc = 0.9461\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9680798053741455\n",
      "precision class 1 = 0.8333333134651184\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9461377060917642\n",
      "AUC of PRC = 0.7646152573396827\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6870228448021668\n",
      "Epoch 83 Batch 0: Train Loss = 0.0959\n",
      "Epoch 83 Batch 20: Train Loss = 0.0868\n",
      "Epoch 83 Batch 40: Train Loss = 0.0950\n",
      "Epoch 83 Batch 60: Train Loss = 0.1496\n",
      "Epoch 83 Batch 80: Train Loss = 0.1067\n",
      "Epoch 83 Batch 100: Train Loss = 0.0974\n",
      "Epoch 83 Batch 120: Train Loss = 0.0819\n",
      "Epoch 83: Loss = 0.1102 Valid loss = 0.1272 roc = 0.9458\n",
      "confusion matrix:\n",
      "[[3878   40]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9695000052452087\n",
      "precision class 1 = 0.8230088353157043\n",
      "recall class 0 = 0.9897907376289368\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9458020922416022\n",
      "AUC of PRC = 0.7671099353831263\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.696629193445203\n",
      "Epoch 84 Batch 0: Train Loss = 0.0648\n",
      "Epoch 84 Batch 20: Train Loss = 0.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 40: Train Loss = 0.0633\n",
      "Epoch 84 Batch 60: Train Loss = 0.1238\n",
      "Epoch 84 Batch 80: Train Loss = 0.1370\n",
      "Epoch 84 Batch 100: Train Loss = 0.1374\n",
      "Epoch 84 Batch 120: Train Loss = 0.1219\n",
      "Epoch 84: Loss = 0.1086 Valid loss = 0.1230 roc = 0.9463\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9630856513977051\n",
      "precision class 0 = 0.9697802066802979\n",
      "precision class 1 = 0.8423423171043396\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.94629266853616\n",
      "AUC of PRC = 0.7707852027799451\n",
      "min(+P, Se) = 0.7175324675324676\n",
      "f1_score = 0.7056603742537014\n",
      "Epoch 85 Batch 0: Train Loss = 0.0862\n",
      "Epoch 85 Batch 20: Train Loss = 0.0947\n",
      "Epoch 85 Batch 40: Train Loss = 0.0861\n",
      "Epoch 85 Batch 60: Train Loss = 0.0764\n",
      "Epoch 85 Batch 80: Train Loss = 0.0902\n",
      "Epoch 85 Batch 100: Train Loss = 0.0546\n",
      "Epoch 85 Batch 120: Train Loss = 0.1242\n",
      "Epoch 85: Loss = 0.1074 Valid loss = 0.1204 roc = 0.9456\n",
      "confusion matrix:\n",
      "[[3892   26]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9669564962387085\n",
      "precision class 1 = 0.8706467747688293\n",
      "recall class 0 = 0.9933639764785767\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9455758636463079\n",
      "AUC of PRC = 0.7665627755428704\n",
      "min(+P, Se) = 0.7184466019417476\n",
      "f1_score = 0.6876227884978444\n",
      "Epoch 86 Batch 0: Train Loss = 0.1193\n",
      "Epoch 86 Batch 20: Train Loss = 0.0933\n",
      "Epoch 86 Batch 40: Train Loss = 0.1079\n",
      "Epoch 86 Batch 60: Train Loss = 0.1002\n",
      "Epoch 86 Batch 80: Train Loss = 0.0579\n",
      "Epoch 86 Batch 100: Train Loss = 0.0667\n",
      "Epoch 86 Batch 120: Train Loss = 0.1212\n",
      "Epoch 86: Loss = 0.1095 Valid loss = 0.1258 roc = 0.9468\n",
      "confusion matrix:\n",
      "[[3889   29]\n",
      " [ 132  176]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.9671723246574402\n",
      "precision class 1 = 0.8585366010665894\n",
      "recall class 0 = 0.9925982356071472\n",
      "recall class 1 = 0.5714285969734192\n",
      "AUC of ROC = 0.9468139058491278\n",
      "AUC of PRC = 0.7689872825537983\n",
      "min(+P, Se) = 0.7142857142857143\n",
      "f1_score = 0.6861598388843116\n",
      "Epoch 87 Batch 0: Train Loss = 0.1006\n",
      "Epoch 87 Batch 20: Train Loss = 0.1360\n",
      "Epoch 87 Batch 40: Train Loss = 0.0762\n",
      "Epoch 87 Batch 60: Train Loss = 0.1212\n",
      "Epoch 87 Batch 80: Train Loss = 0.0550\n",
      "Epoch 87 Batch 100: Train Loss = 0.1350\n",
      "Epoch 87 Batch 120: Train Loss = 0.0744\n",
      "Epoch 87: Loss = 0.1073 Valid loss = 0.1227 roc = 0.9478\n",
      "confusion matrix:\n",
      "[[3886   32]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9628490209579468\n",
      "precision class 0 = 0.968835711479187\n",
      "precision class 1 = 0.8511627912521362\n",
      "recall class 0 = 0.9918325543403625\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.9478489223895044\n",
      "AUC of PRC = 0.77004974557538\n",
      "min(+P, Se) = 0.7225806451612903\n",
      "f1_score = 0.6998087694231704\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 88 Batch 0: Train Loss = 0.1508\n",
      "Epoch 88 Batch 20: Train Loss = 0.0831\n",
      "Epoch 88 Batch 40: Train Loss = 0.0705\n",
      "Epoch 88 Batch 60: Train Loss = 0.0584\n",
      "Epoch 88 Batch 80: Train Loss = 0.0614\n",
      "Epoch 88 Batch 100: Train Loss = 0.1055\n",
      "Epoch 88 Batch 120: Train Loss = 0.1456\n",
      "Epoch 88: Loss = 0.1066 Valid loss = 0.1247 roc = 0.9440\n",
      "confusion matrix:\n",
      "[[3883   35]\n",
      " [ 131  177]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9673642516136169\n",
      "precision class 1 = 0.8349056839942932\n",
      "recall class 0 = 0.9910668730735779\n",
      "recall class 1 = 0.5746753215789795\n",
      "AUC of ROC = 0.9439574590799706\n",
      "AUC of PRC = 0.7693928525302229\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.6807692652341185\n",
      "Epoch 89 Batch 0: Train Loss = 0.1187\n",
      "Epoch 89 Batch 20: Train Loss = 0.0915\n",
      "Epoch 89 Batch 40: Train Loss = 0.0588\n",
      "Epoch 89 Batch 60: Train Loss = 0.0754\n",
      "Epoch 89 Batch 80: Train Loss = 0.0999\n",
      "Epoch 89 Batch 100: Train Loss = 0.1437\n",
      "Epoch 89 Batch 120: Train Loss = 0.1183\n",
      "Epoch 89: Loss = 0.1054 Valid loss = 0.1180 roc = 0.9479\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9681195616722107\n",
      "precision class 1 = 0.8530805706977844\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9479268179497888\n",
      "AUC of PRC = 0.7765126359848535\n",
      "min(+P, Se) = 0.7207792207792207\n",
      "f1_score = 0.6936415696704311\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "\n",
      "------------ Save best-sum model ------------\n",
      "\n",
      "Epoch 90 Batch 0: Train Loss = 0.0671\n",
      "Epoch 90 Batch 20: Train Loss = 0.0994\n",
      "Epoch 90 Batch 40: Train Loss = 0.0644\n",
      "Epoch 90 Batch 60: Train Loss = 0.0789\n",
      "Epoch 90 Batch 80: Train Loss = 0.0745\n",
      "Epoch 90 Batch 100: Train Loss = 0.0765\n",
      "Epoch 90 Batch 120: Train Loss = 0.1788\n",
      "Epoch 90: Loss = 0.1062 Valid loss = 0.1287 roc = 0.9420\n",
      "confusion matrix:\n",
      "[[3891   27]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9621391296386719\n",
      "precision class 0 = 0.9669483304023743\n",
      "precision class 1 = 0.8663366436958313\n",
      "recall class 0 = 0.9931087493896484\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9419545487692502\n",
      "AUC of PRC = 0.7655937553828446\n",
      "min(+P, Se) = 0.6891025641025641\n",
      "f1_score = 0.6862745089991098\n",
      "Epoch 91 Batch 0: Train Loss = 0.1039\n",
      "Epoch 91 Batch 20: Train Loss = 0.1535\n",
      "Epoch 91 Batch 40: Train Loss = 0.1087\n",
      "Epoch 91 Batch 60: Train Loss = 0.0855\n",
      "Epoch 91 Batch 80: Train Loss = 0.1199\n",
      "Epoch 91 Batch 100: Train Loss = 0.0946\n",
      "Epoch 91 Batch 120: Train Loss = 0.1529\n",
      "Epoch 91: Loss = 0.1131 Valid loss = 0.1218 roc = 0.9454\n",
      "confusion matrix:\n",
      "[[3870   48]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9689534306526184\n",
      "precision class 1 = 0.7931034564971924\n",
      "recall class 0 = 0.9877488613128662\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9453579218127457\n",
      "AUC of PRC = 0.7715453971807323\n",
      "min(+P, Se) = 0.711038961038961\n",
      "f1_score = 0.6814814683995288\n",
      "Epoch 92 Batch 0: Train Loss = 0.0689\n",
      "Epoch 92 Batch 20: Train Loss = 0.0617\n",
      "Epoch 92 Batch 40: Train Loss = 0.0767\n",
      "Epoch 92 Batch 60: Train Loss = 0.1211\n",
      "Epoch 92 Batch 80: Train Loss = 0.1230\n",
      "Epoch 92 Batch 100: Train Loss = 0.0695\n",
      "Epoch 92 Batch 120: Train Loss = 0.1043\n",
      "Epoch 92: Loss = 0.1048 Valid loss = 0.1281 roc = 0.9449\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 117  191]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9706987142562866\n",
      "precision class 1 = 0.8197425007820129\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.6201298832893372\n",
      "AUC of ROC = 0.9449386116690863\n",
      "AUC of PRC = 0.7624951898328738\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.7060998279581823\n",
      "Epoch 93 Batch 0: Train Loss = 0.0796\n",
      "Epoch 93 Batch 20: Train Loss = 0.0823\n",
      "Epoch 93 Batch 40: Train Loss = 0.0728\n",
      "Epoch 93 Batch 60: Train Loss = 0.1214\n",
      "Epoch 93 Batch 80: Train Loss = 0.0979\n",
      "Epoch 93 Batch 100: Train Loss = 0.1271\n",
      "Epoch 93 Batch 120: Train Loss = 0.0747\n",
      "Epoch 93: Loss = 0.1085 Valid loss = 0.1242 roc = 0.9442\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 132  176]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.9671151041984558\n",
      "precision class 1 = 0.8301886916160583\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5714285969734192\n",
      "AUC of ROC = 0.9441530266568552\n",
      "AUC of PRC = 0.7589462087358468\n",
      "min(+P, Se) = 0.6753246753246753\n",
      "f1_score = 0.6769230989591608\n",
      "Epoch 94 Batch 0: Train Loss = 0.1150\n",
      "Epoch 94 Batch 20: Train Loss = 0.1377\n",
      "Epoch 94 Batch 40: Train Loss = 0.0732\n",
      "Epoch 94 Batch 60: Train Loss = 0.1269\n",
      "Epoch 94 Batch 80: Train Loss = 0.1150\n",
      "Epoch 94 Batch 100: Train Loss = 0.0746\n",
      "Epoch 94 Batch 120: Train Loss = 0.0805\n",
      "Epoch 94: Loss = 0.1066 Valid loss = 0.1212 roc = 0.9471\n",
      "confusion matrix:\n",
      "[[3868   50]\n",
      " [ 112  196]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9718592762947083\n",
      "precision class 1 = 0.7967479825019836\n",
      "recall class 0 = 0.9872384071350098\n",
      "recall class 1 = 0.6363636255264282\n",
      "AUC of ROC = 0.947135432204345\n",
      "AUC of PRC = 0.7691187013400022\n",
      "min(+P, Se) = 0.7022653721682848\n",
      "f1_score = 0.7075811972324973\n",
      "Epoch 95 Batch 0: Train Loss = 0.0821\n",
      "Epoch 95 Batch 20: Train Loss = 0.0707\n",
      "Epoch 95 Batch 40: Train Loss = 0.1184\n",
      "Epoch 95 Batch 60: Train Loss = 0.0740\n",
      "Epoch 95 Batch 80: Train Loss = 0.0921\n",
      "Epoch 95 Batch 100: Train Loss = 0.0973\n",
      "Epoch 95 Batch 120: Train Loss = 0.1272\n",
      "Epoch 95: Loss = 0.1055 Valid loss = 0.1278 roc = 0.9466\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 124  184]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9690232276916504\n",
      "precision class 1 = 0.8251121044158936\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9465553588830771\n",
      "AUC of PRC = 0.7689201131512959\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6930319972666037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 0: Train Loss = 0.1002\n",
      "Epoch 96 Batch 20: Train Loss = 0.0657\n",
      "Epoch 96 Batch 40: Train Loss = 0.0916\n",
      "Epoch 96 Batch 60: Train Loss = 0.0905\n",
      "Epoch 96 Batch 80: Train Loss = 0.1275\n",
      "Epoch 96 Batch 100: Train Loss = 0.0898\n",
      "Epoch 96 Batch 120: Train Loss = 0.1116\n",
      "Epoch 96: Loss = 0.1037 Valid loss = 0.1287 roc = 0.9439\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 139  169]]\n",
      "accuracy = 0.955986738204956\n",
      "precision class 0 = 0.9653366804122925\n",
      "precision class 1 = 0.7824074029922485\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.548701286315918\n",
      "AUC of ROC = 0.9438853642528987\n",
      "AUC of PRC = 0.7358453720505408\n",
      "min(+P, Se) = 0.6559485530546624\n",
      "f1_score = 0.6450381578803652\n",
      "Epoch 97 Batch 0: Train Loss = 0.1230\n",
      "Epoch 97 Batch 20: Train Loss = 0.1066\n",
      "Epoch 97 Batch 40: Train Loss = 0.1085\n",
      "Epoch 97 Batch 60: Train Loss = 0.0828\n",
      "Epoch 97 Batch 80: Train Loss = 0.1424\n",
      "Epoch 97 Batch 100: Train Loss = 0.1154\n",
      "Epoch 97 Batch 120: Train Loss = 0.1007\n",
      "Epoch 97: Loss = 0.1029 Valid loss = 0.1274 roc = 0.9469\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9668906927108765\n",
      "precision class 1 = 0.8373205661773682\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9469373785989406\n",
      "AUC of PRC = 0.7658311750064154\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6769826141295266\n",
      "Epoch 98 Batch 0: Train Loss = 0.0465\n",
      "Epoch 98 Batch 20: Train Loss = 0.0687\n",
      "Epoch 98 Batch 40: Train Loss = 0.1481\n",
      "Epoch 98 Batch 60: Train Loss = 0.1873\n",
      "Epoch 98 Batch 80: Train Loss = 0.1623\n",
      "Epoch 98 Batch 100: Train Loss = 0.1460\n",
      "Epoch 98 Batch 120: Train Loss = 0.0871\n",
      "Epoch 98: Loss = 0.1030 Valid loss = 0.1187 roc = 0.9481\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9699323773384094\n",
      "precision class 1 = 0.800000011920929\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9480792943656651\n",
      "AUC of PRC = 0.7715047922985493\n",
      "min(+P, Se) = 0.7064516129032258\n",
      "f1_score = 0.6924493176839215\n",
      "Epoch 99 Batch 0: Train Loss = 0.0698\n",
      "Epoch 99 Batch 20: Train Loss = 0.1005\n",
      "Epoch 99 Batch 40: Train Loss = 0.0717\n",
      "Epoch 99 Batch 60: Train Loss = 0.0833\n",
      "Epoch 99 Batch 80: Train Loss = 0.0754\n",
      "Epoch 99 Batch 100: Train Loss = 0.1284\n",
      "Epoch 99 Batch 120: Train Loss = 0.1223\n",
      "Epoch 99: Loss = 0.1038 Valid loss = 0.1331 roc = 0.9475\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 129  179]]\n",
      "accuracy = 0.959062933921814\n",
      "precision class 0 = 0.9677741527557373\n",
      "precision class 1 = 0.8026905655860901\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9474851335494521\n",
      "AUC of PRC = 0.7570314181363622\n",
      "min(+P, Se) = 0.6935483870967742\n",
      "f1_score = 0.6741996167030032\n",
      "Epoch 100 Batch 0: Train Loss = 0.1174\n",
      "Epoch 100 Batch 20: Train Loss = 0.1144\n",
      "Epoch 100 Batch 40: Train Loss = 0.1249\n",
      "Epoch 100 Batch 60: Train Loss = 0.2001\n",
      "Epoch 100 Batch 80: Train Loss = 0.0763\n",
      "Epoch 100 Batch 100: Train Loss = 0.1131\n",
      "Epoch 100 Batch 120: Train Loss = 0.0886\n",
      "Epoch 100: Loss = 0.1050 Valid loss = 0.1159 roc = 0.9506\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 119  189]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9701828956604004\n",
      "precision class 1 = 0.8042553067207336\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6136363744735718\n",
      "AUC of ROC = 0.950564494209211\n",
      "AUC of PRC = 0.7773088533746836\n",
      "min(+P, Se) = 0.7028753993610224\n",
      "f1_score = 0.6961325697392861\n",
      "------------ Save best model - AUROC: 0.9506 ------------\n",
      "\n",
      "------------ Save best-prc model ------------\n",
      "\n",
      "Epoch 101 Batch 0: Train Loss = 0.0803\n",
      "Epoch 101 Batch 20: Train Loss = 0.0903\n",
      "Epoch 101 Batch 40: Train Loss = 0.0955\n",
      "Epoch 101 Batch 60: Train Loss = 0.0862\n",
      "Epoch 101 Batch 80: Train Loss = 0.1610\n",
      "Epoch 101 Batch 100: Train Loss = 0.1030\n",
      "Epoch 101 Batch 120: Train Loss = 0.1037\n",
      "Epoch 101: Loss = 0.1024 Valid loss = 0.1213 roc = 0.9471\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 114  194]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9713783860206604\n",
      "precision class 1 = 0.798353910446167\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6298701167106628\n",
      "AUC of ROC = 0.9471155439761871\n",
      "AUC of PRC = 0.7680421241135269\n",
      "min(+P, Se) = 0.6925566343042071\n",
      "f1_score = 0.7041741914455235\n",
      "Epoch 102 Batch 0: Train Loss = 0.0732\n",
      "Epoch 102 Batch 20: Train Loss = 0.0889\n",
      "Epoch 102 Batch 40: Train Loss = 0.1338\n",
      "Epoch 102 Batch 60: Train Loss = 0.0822\n",
      "Epoch 102 Batch 80: Train Loss = 0.1496\n",
      "Epoch 102 Batch 100: Train Loss = 0.0815\n",
      "Epoch 102 Batch 120: Train Loss = 0.1587\n",
      "Epoch 102: Loss = 0.1013 Valid loss = 0.1203 roc = 0.9446\n",
      "confusion matrix:\n",
      "[[3881   37]\n",
      " [ 126  182]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9685550332069397\n",
      "precision class 1 = 0.8310502171516418\n",
      "recall class 0 = 0.9905564188957214\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9445872529716328\n",
      "AUC of PRC = 0.7651472008596194\n",
      "min(+P, Se) = 0.6990291262135923\n",
      "f1_score = 0.6907020649241353\n",
      "Epoch 103 Batch 0: Train Loss = 0.0631\n",
      "Epoch 103 Batch 20: Train Loss = 0.1450\n",
      "Epoch 103 Batch 40: Train Loss = 0.0851\n",
      "Epoch 103 Batch 60: Train Loss = 0.1355\n",
      "Epoch 103 Batch 80: Train Loss = 0.0791\n",
      "Epoch 103 Batch 100: Train Loss = 0.0486\n",
      "Epoch 103 Batch 120: Train Loss = 0.0932\n",
      "Epoch 103: Loss = 0.1005 Valid loss = 0.1255 roc = 0.9471\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.969273030757904\n",
      "precision class 1 = 0.8295964002609253\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9471097432429745\n",
      "AUC of PRC = 0.770530777881303\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6967984932387027\n",
      "Epoch 104 Batch 0: Train Loss = 0.1501\n",
      "Epoch 104 Batch 20: Train Loss = 0.0884\n",
      "Epoch 104 Batch 40: Train Loss = 0.1186\n",
      "Epoch 104 Batch 60: Train Loss = 0.0956\n",
      "Epoch 104 Batch 80: Train Loss = 0.0987\n",
      "Epoch 104 Batch 100: Train Loss = 0.0741\n",
      "Epoch 104 Batch 120: Train Loss = 0.1244\n",
      "Epoch 104: Loss = 0.1019 Valid loss = 0.1237 roc = 0.9475\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.969265341758728\n",
      "precision class 1 = 0.8258928656578064\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9474801614924127\n",
      "AUC of PRC = 0.7719387382750287\n",
      "min(+P, Se) = 0.6915584415584416\n",
      "f1_score = 0.6954886999156679\n",
      "Epoch 105 Batch 0: Train Loss = 0.1235\n",
      "Epoch 105 Batch 20: Train Loss = 0.0848\n",
      "Epoch 105 Batch 40: Train Loss = 0.0772\n",
      "Epoch 105 Batch 60: Train Loss = 0.0795\n",
      "Epoch 105 Batch 80: Train Loss = 0.1125\n",
      "Epoch 105 Batch 100: Train Loss = 0.0869\n",
      "Epoch 105 Batch 120: Train Loss = 0.0574\n",
      "Epoch 105: Loss = 0.0994 Valid loss = 0.1270 roc = 0.9471\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9687812328338623\n",
      "precision class 1 = 0.8243243098258972\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.9470707954628322\n",
      "AUC of PRC = 0.7691040682272787\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6905660352625427\n",
      "Epoch 106 Batch 0: Train Loss = 0.0887\n",
      "Epoch 106 Batch 20: Train Loss = 0.0819\n",
      "Epoch 106 Batch 40: Train Loss = 0.1093\n",
      "Epoch 106 Batch 60: Train Loss = 0.1002\n",
      "Epoch 106 Batch 80: Train Loss = 0.0924\n",
      "Epoch 106 Batch 100: Train Loss = 0.1244\n",
      "Epoch 106 Batch 120: Train Loss = 0.1203\n",
      "Epoch 106: Loss = 0.0977 Valid loss = 0.1215 roc = 0.9481\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 111  197]]\n",
      "accuracy = 0.9621391296386719\n",
      "precision class 0 = 0.9721105694770813\n",
      "precision class 1 = 0.8008130192756653\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6396104097366333\n",
      "AUC of ROC = 0.9481306722884059\n",
      "AUC of PRC = 0.7764779952082618\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.7111913231478163\n",
      "Epoch 107 Batch 0: Train Loss = 0.0915\n",
      "Epoch 107 Batch 20: Train Loss = 0.1397\n",
      "Epoch 107 Batch 40: Train Loss = 0.0961\n",
      "Epoch 107 Batch 60: Train Loss = 0.1947\n",
      "Epoch 107 Batch 80: Train Loss = 0.0795\n",
      "Epoch 107 Batch 100: Train Loss = 0.0887\n",
      "Epoch 107 Batch 120: Train Loss = 0.0964\n",
      "Epoch 107: Loss = 0.0993 Valid loss = 0.1191 roc = 0.9471\n",
      "confusion matrix:\n",
      "[[3870   48]\n",
      " [ 115  193]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9711417555809021\n",
      "precision class 1 = 0.8008298873901367\n",
      "recall class 0 = 0.9877488613128662\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.947108085890628\n",
      "AUC of PRC = 0.7742543287483502\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.7030965534830009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 Batch 0: Train Loss = 0.0567\n",
      "Epoch 108 Batch 20: Train Loss = 0.0997\n",
      "Epoch 108 Batch 40: Train Loss = 0.1184\n",
      "Epoch 108 Batch 60: Train Loss = 0.0649\n",
      "Epoch 108 Batch 80: Train Loss = 0.0800\n",
      "Epoch 108 Batch 100: Train Loss = 0.0525\n",
      "Epoch 108 Batch 120: Train Loss = 0.1391\n",
      "Epoch 108: Loss = 0.0964 Valid loss = 0.1332 roc = 0.9463\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9619024991989136\n",
      "precision class 0 = 0.969273030757904\n",
      "precision class 1 = 0.8295964002609253\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9462910111838136\n",
      "AUC of PRC = 0.7629561591525194\n",
      "min(+P, Se) = 0.6881028938906752\n",
      "f1_score = 0.6967984932387027\n",
      "Epoch 109 Batch 0: Train Loss = 0.1249\n",
      "Epoch 109 Batch 20: Train Loss = 0.0985\n",
      "Epoch 109 Batch 40: Train Loss = 0.0807\n",
      "Epoch 109 Batch 60: Train Loss = 0.0698\n",
      "Epoch 109 Batch 80: Train Loss = 0.0850\n",
      "Epoch 109 Batch 100: Train Loss = 0.1154\n",
      "Epoch 109 Batch 120: Train Loss = 0.1658\n",
      "Epoch 109: Loss = 0.0971 Valid loss = 0.1243 roc = 0.9462\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9699549078941345\n",
      "precision class 1 = 0.8103448152542114\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9462487486989783\n",
      "AUC of PRC = 0.7745398064665941\n",
      "min(+P, Se) = 0.7055016181229773\n",
      "f1_score = 0.6962962786487427\n",
      "Epoch 110 Batch 0: Train Loss = 0.1531\n",
      "Epoch 110 Batch 20: Train Loss = 0.0958\n",
      "Epoch 110 Batch 40: Train Loss = 0.0797\n",
      "Epoch 110 Batch 60: Train Loss = 0.0920\n",
      "Epoch 110 Batch 80: Train Loss = 0.0838\n",
      "Epoch 110 Batch 100: Train Loss = 0.1081\n",
      "Epoch 110 Batch 120: Train Loss = 0.0791\n",
      "Epoch 110: Loss = 0.0977 Valid loss = 0.1290 roc = 0.9467\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 129  179]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9678544998168945\n",
      "precision class 1 = 0.8403756022453308\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9467302095556306\n",
      "AUC of PRC = 0.7715607222424062\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6871401197669879\n",
      "Epoch 111 Batch 0: Train Loss = 0.1063\n",
      "Epoch 111 Batch 20: Train Loss = 0.0791\n",
      "Epoch 111 Batch 40: Train Loss = 0.0590\n",
      "Epoch 111 Batch 60: Train Loss = 0.0673\n",
      "Epoch 111 Batch 80: Train Loss = 0.0829\n",
      "Epoch 111 Batch 100: Train Loss = 0.0876\n",
      "Epoch 111 Batch 120: Train Loss = 0.0875\n",
      "Epoch 111: Loss = 0.0966 Valid loss = 0.1239 roc = 0.9455\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9690309762954712\n",
      "precision class 1 = 0.8288288116455078\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9454888526481174\n",
      "AUC of PRC = 0.7639792275806222\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6943395998809803\n",
      "Epoch 112 Batch 0: Train Loss = 0.0704\n",
      "Epoch 112 Batch 20: Train Loss = 0.1147\n",
      "Epoch 112 Batch 40: Train Loss = 0.0718\n",
      "Epoch 112 Batch 60: Train Loss = 0.0951\n",
      "Epoch 112 Batch 80: Train Loss = 0.0957\n",
      "Epoch 112 Batch 100: Train Loss = 0.1355\n",
      "Epoch 112 Batch 120: Train Loss = 0.0990\n",
      "Epoch 112: Loss = 0.0959 Valid loss = 0.1235 roc = 0.9467\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.970403790473938\n",
      "precision class 1 = 0.7949790954589844\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9467252374985913\n",
      "AUC of PRC = 0.769958107849244\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6946983787945726\n",
      "Epoch 113 Batch 0: Train Loss = 0.0612\n",
      "Epoch 113 Batch 20: Train Loss = 0.0908\n",
      "Epoch 113 Batch 40: Train Loss = 0.1540\n",
      "Epoch 113 Batch 60: Train Loss = 0.0465\n",
      "Epoch 113 Batch 80: Train Loss = 0.1108\n",
      "Epoch 113 Batch 100: Train Loss = 0.0632\n",
      "Epoch 113 Batch 120: Train Loss = 0.1017\n",
      "Epoch 113: Loss = 0.0950 Valid loss = 0.1398 roc = 0.9430\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 145  163]]\n",
      "accuracy = 0.9571698904037476\n",
      "precision class 0 = 0.9639930725097656\n",
      "precision class 1 = 0.8190954923629761\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5292207598686218\n",
      "AUC of ROC = 0.9430442579370604\n",
      "AUC of PRC = 0.743386771233098\n",
      "min(+P, Se) = 0.672077922077922\n",
      "f1_score = 0.6429980463688332\n",
      "Epoch 114 Batch 0: Train Loss = 0.1145\n",
      "Epoch 114 Batch 20: Train Loss = 0.1110\n",
      "Epoch 114 Batch 40: Train Loss = 0.0673\n",
      "Epoch 114 Batch 60: Train Loss = 0.1581\n",
      "Epoch 114 Batch 80: Train Loss = 0.1260\n",
      "Epoch 114 Batch 100: Train Loss = 0.0609\n",
      "Epoch 114 Batch 120: Train Loss = 0.1487\n",
      "Epoch 114: Loss = 0.0979 Valid loss = 0.1254 roc = 0.9454\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 124  184]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.9689611792564392\n",
      "precision class 1 = 0.7965368032455444\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.5974025726318359\n",
      "AUC of ROC = 0.9453570931365725\n",
      "AUC of PRC = 0.761477993807335\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6827458118905823\n",
      "Epoch 115 Batch 0: Train Loss = 0.1062\n",
      "Epoch 115 Batch 20: Train Loss = 0.1613\n",
      "Epoch 115 Batch 40: Train Loss = 0.0955\n",
      "Epoch 115 Batch 60: Train Loss = 0.1008\n",
      "Epoch 115 Batch 80: Train Loss = 0.1088\n",
      "Epoch 115 Batch 100: Train Loss = 0.0678\n",
      "Epoch 115 Batch 120: Train Loss = 0.0889\n",
      "Epoch 115: Loss = 0.0950 Valid loss = 0.1269 roc = 0.9479\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 119  189]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9701828956604004\n",
      "precision class 1 = 0.8042553067207336\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6136363744735718\n",
      "AUC of ROC = 0.9479467061779465\n",
      "AUC of PRC = 0.7654676094432846\n",
      "min(+P, Se) = 0.6893203883495146\n",
      "f1_score = 0.6961325697392861\n",
      "Epoch 116 Batch 0: Train Loss = 0.0897\n",
      "Epoch 116 Batch 20: Train Loss = 0.0981\n",
      "Epoch 116 Batch 40: Train Loss = 0.0672\n",
      "Epoch 116 Batch 60: Train Loss = 0.0443\n",
      "Epoch 116 Batch 80: Train Loss = 0.1125\n",
      "Epoch 116 Batch 100: Train Loss = 0.0657\n",
      "Epoch 116 Batch 120: Train Loss = 0.0674\n",
      "Epoch 116: Loss = 0.0961 Valid loss = 0.1303 roc = 0.9454\n",
      "confusion matrix:\n",
      "[[3886   32]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9669072031974792\n",
      "precision class 1 = 0.8454106450080872\n",
      "recall class 0 = 0.9918325543403625\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9453927262120218\n",
      "AUC of PRC = 0.7622940432453569\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6796116520985658\n",
      "Epoch 117 Batch 0: Train Loss = 0.1319\n",
      "Epoch 117 Batch 20: Train Loss = 0.1046\n",
      "Epoch 117 Batch 40: Train Loss = 0.1135\n",
      "Epoch 117 Batch 60: Train Loss = 0.1111\n",
      "Epoch 117 Batch 80: Train Loss = 0.0870\n",
      "Epoch 117 Batch 100: Train Loss = 0.1269\n",
      "Epoch 117 Batch 120: Train Loss = 0.0731\n",
      "Epoch 117: Loss = 0.0940 Valid loss = 0.1313 roc = 0.9430\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9685078859329224\n",
      "precision class 1 = 0.8088889122009277\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9429953660428392\n",
      "AUC of PRC = 0.7600871360868263\n",
      "min(+P, Se) = 0.6688311688311688\n",
      "f1_score = 0.6829268485623982\n",
      "Epoch 118 Batch 0: Train Loss = 0.0724\n",
      "Epoch 118 Batch 20: Train Loss = 0.0887\n",
      "Epoch 118 Batch 40: Train Loss = 0.0580\n",
      "Epoch 118 Batch 60: Train Loss = 0.0996\n",
      "Epoch 118 Batch 80: Train Loss = 0.1023\n",
      "Epoch 118 Batch 100: Train Loss = 0.0920\n",
      "Epoch 118 Batch 120: Train Loss = 0.0817\n",
      "Epoch 118: Loss = 0.0943 Valid loss = 0.1325 roc = 0.9446\n",
      "confusion matrix:\n",
      "[[3849   69]\n",
      " [ 109  199]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.9724608659744263\n",
      "precision class 1 = 0.7425373196601868\n",
      "recall class 0 = 0.982388973236084\n",
      "recall class 1 = 0.6461039185523987\n",
      "AUC of ROC = 0.944646917656106\n",
      "AUC of PRC = 0.7592619396512345\n",
      "min(+P, Se) = 0.6925566343042071\n",
      "f1_score = 0.6909722377557628\n",
      "Epoch 119 Batch 0: Train Loss = 0.0822\n",
      "Epoch 119 Batch 20: Train Loss = 0.0878\n",
      "Epoch 119 Batch 40: Train Loss = 0.1390\n",
      "Epoch 119 Batch 60: Train Loss = 0.1113\n",
      "Epoch 119 Batch 80: Train Loss = 0.1089\n",
      "Epoch 119 Batch 100: Train Loss = 0.1268\n",
      "Epoch 119 Batch 120: Train Loss = 0.1183\n",
      "Epoch 119: Loss = 0.1082 Valid loss = 0.1196 roc = 0.9502\n",
      "confusion matrix:\n",
      "[[3862   56]\n",
      " [ 112  196]]\n",
      "accuracy = 0.9602460861206055\n",
      "precision class 0 = 0.9718168377876282\n",
      "precision class 1 = 0.7777777910232544\n",
      "recall class 0 = 0.9857069849967957\n",
      "recall class 1 = 0.6363636255264282\n",
      "AUC of ROC = 0.950208992130891\n",
      "AUC of PRC = 0.7739983216191663\n",
      "min(+P, Se) = 0.698051948051948\n",
      "f1_score = 0.6999999988079069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 Batch 0: Train Loss = 0.1197\n",
      "Epoch 120 Batch 20: Train Loss = 0.1184\n",
      "Epoch 120 Batch 40: Train Loss = 0.1350\n",
      "Epoch 120 Batch 60: Train Loss = 0.1022\n",
      "Epoch 120 Batch 80: Train Loss = 0.1206\n",
      "Epoch 120 Batch 100: Train Loss = 0.0757\n",
      "Epoch 120 Batch 120: Train Loss = 0.0833\n",
      "Epoch 120: Loss = 0.1002 Valid loss = 0.1374 roc = 0.9450\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 138  170]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9656887054443359\n",
      "precision class 1 = 0.8333333134651184\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.551948070526123\n",
      "AUC of ROC = 0.9449518704878583\n",
      "AUC of PRC = 0.7476225172882403\n",
      "min(+P, Se) = 0.6796116504854369\n",
      "f1_score = 0.664062535710401\n",
      "Epoch 121 Batch 0: Train Loss = 0.0899\n",
      "Epoch 121 Batch 20: Train Loss = 0.1211\n",
      "Epoch 121 Batch 40: Train Loss = 0.0944\n",
      "Epoch 121 Batch 60: Train Loss = 0.1788\n",
      "Epoch 121 Batch 80: Train Loss = 0.0944\n",
      "Epoch 121 Batch 100: Train Loss = 0.0580\n",
      "Epoch 121 Batch 120: Train Loss = 0.0390\n",
      "Epoch 121: Loss = 0.0950 Valid loss = 0.1307 roc = 0.9481\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9680559039115906\n",
      "precision class 1 = 0.8219178318977356\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9480867524512241\n",
      "AUC of PRC = 0.7622440047533418\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.683111913590182\n",
      "Epoch 122 Batch 0: Train Loss = 0.0847\n",
      "Epoch 122 Batch 20: Train Loss = 0.1155\n",
      "Epoch 122 Batch 40: Train Loss = 0.0479\n",
      "Epoch 122 Batch 60: Train Loss = 0.0422\n",
      "Epoch 122 Batch 80: Train Loss = 0.1091\n",
      "Epoch 122 Batch 100: Train Loss = 0.0662\n",
      "Epoch 122 Batch 120: Train Loss = 0.0957\n",
      "Epoch 122: Loss = 0.0945 Valid loss = 0.1374 roc = 0.9476\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 122  186]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.969477117061615\n",
      "precision class 1 = 0.8122270703315735\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.6038960814476013\n",
      "AUC of ROC = 0.9476177217371704\n",
      "AUC of PRC = 0.7595526983506137\n",
      "min(+P, Se) = 0.6763754045307443\n",
      "f1_score = 0.6927374139779469\n",
      "Epoch 123 Batch 0: Train Loss = 0.0766\n",
      "Epoch 123 Batch 20: Train Loss = 0.0714\n",
      "Epoch 123 Batch 40: Train Loss = 0.0795\n",
      "Epoch 123 Batch 60: Train Loss = 0.0869\n",
      "Epoch 123 Batch 80: Train Loss = 0.0747\n",
      "Epoch 123 Batch 100: Train Loss = 0.0602\n",
      "Epoch 123 Batch 120: Train Loss = 0.0861\n",
      "Epoch 123: Loss = 0.0969 Valid loss = 0.1273 roc = 0.9450\n",
      "confusion matrix:\n",
      "[[3874   44]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9581164121627808\n",
      "precision class 0 = 0.9668080806732178\n",
      "precision class 1 = 0.7990867495536804\n",
      "recall class 0 = 0.9887697696685791\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9450181645817173\n",
      "AUC of PRC = 0.7567612067149401\n",
      "min(+P, Se) = 0.6688311688311688\n",
      "f1_score = 0.6641366157751881\n",
      "Epoch 124 Batch 0: Train Loss = 0.0836\n",
      "Epoch 124 Batch 20: Train Loss = 0.1140\n",
      "Epoch 124 Batch 40: Train Loss = 0.0541\n",
      "Epoch 124 Batch 60: Train Loss = 0.0660\n",
      "Epoch 124 Batch 80: Train Loss = 0.0641\n",
      "Epoch 124 Batch 100: Train Loss = 0.0994\n",
      "Epoch 124 Batch 120: Train Loss = 0.1115\n",
      "Epoch 124: Loss = 0.0983 Valid loss = 0.1244 roc = 0.9454\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 116  192]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9709346294403076\n",
      "precision class 1 = 0.8170212507247925\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9453935548881951\n",
      "AUC of PRC = 0.7690616694484507\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.7071823007886627\n",
      "Epoch 125 Batch 0: Train Loss = 0.0911\n",
      "Epoch 125 Batch 20: Train Loss = 0.1057\n",
      "Epoch 125 Batch 40: Train Loss = 0.0751\n",
      "Epoch 125 Batch 60: Train Loss = 0.0805\n",
      "Epoch 125 Batch 80: Train Loss = 0.0864\n",
      "Epoch 125 Batch 100: Train Loss = 0.0865\n",
      "Epoch 125 Batch 120: Train Loss = 0.0819\n",
      "Epoch 125: Loss = 0.0983 Valid loss = 0.1285 roc = 0.9450\n",
      "confusion matrix:\n",
      "[[3873   45]\n",
      " [ 133  175]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.966799795627594\n",
      "precision class 1 = 0.7954545617103577\n",
      "recall class 0 = 0.9885145425796509\n",
      "recall class 1 = 0.5681818127632141\n",
      "AUC of ROC = 0.9450007623820793\n",
      "AUC of PRC = 0.7462801305900021\n",
      "min(+P, Se) = 0.6688311688311688\n",
      "f1_score = 0.6628787898355059\n",
      "Epoch 126 Batch 0: Train Loss = 0.1083\n",
      "Epoch 126 Batch 20: Train Loss = 0.1114\n",
      "Epoch 126 Batch 40: Train Loss = 0.0872\n",
      "Epoch 126 Batch 60: Train Loss = 0.1627\n",
      "Epoch 126 Batch 80: Train Loss = 0.0576\n",
      "Epoch 126 Batch 100: Train Loss = 0.0871\n",
      "Epoch 126 Batch 120: Train Loss = 0.1039\n",
      "Epoch 126: Loss = 0.0969 Valid loss = 0.1268 roc = 0.9467\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9680638909339905\n",
      "precision class 1 = 0.8256880640983582\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9466945764801814\n",
      "AUC of PRC = 0.7623287391364658\n",
      "min(+P, Se) = 0.686084142394822\n",
      "f1_score = 0.6844106519528524\n",
      "Epoch 127 Batch 0: Train Loss = 0.1233\n",
      "Epoch 127 Batch 20: Train Loss = 0.0477\n",
      "Epoch 127 Batch 40: Train Loss = 0.1088\n",
      "Epoch 127 Batch 60: Train Loss = 0.0969\n",
      "Epoch 127 Batch 80: Train Loss = 0.1074\n",
      "Epoch 127 Batch 100: Train Loss = 0.0969\n",
      "Epoch 127 Batch 120: Train Loss = 0.1174\n",
      "Epoch 127: Loss = 0.0951 Valid loss = 0.1246 roc = 0.9488\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 116  192]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9709054231643677\n",
      "precision class 1 = 0.8033472895622253\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.6233766078948975\n",
      "AUC of ROC = 0.9487753823511864\n",
      "AUC of PRC = 0.7728602264884303\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.702010933299523\n",
      "Epoch 128 Batch 0: Train Loss = 0.0975\n",
      "Epoch 128 Batch 20: Train Loss = 0.1103\n",
      "Epoch 128 Batch 40: Train Loss = 0.1332\n",
      "Epoch 128 Batch 60: Train Loss = 0.1121\n",
      "Epoch 128 Batch 80: Train Loss = 0.1024\n",
      "Epoch 128 Batch 100: Train Loss = 0.1153\n",
      "Epoch 128 Batch 120: Train Loss = 0.1082\n",
      "Epoch 128: Loss = 0.0945 Valid loss = 0.1303 roc = 0.9467\n",
      "confusion matrix:\n",
      "[[3884   34]\n",
      " [ 131  177]]\n",
      "accuracy = 0.9609559774398804\n",
      "precision class 0 = 0.9673723578453064\n",
      "precision class 1 = 0.8388625383377075\n",
      "recall class 0 = 0.9913221001625061\n",
      "recall class 1 = 0.5746753215789795\n",
      "AUC of ROC = 0.9467467830790954\n",
      "AUC of PRC = 0.766052396757877\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6820809157643563\n",
      "Epoch 129 Batch 0: Train Loss = 0.0819\n",
      "Epoch 129 Batch 20: Train Loss = 0.0507\n",
      "Epoch 129 Batch 40: Train Loss = 0.0996\n",
      "Epoch 129 Batch 60: Train Loss = 0.1549\n",
      "Epoch 129 Batch 80: Train Loss = 0.0889\n",
      "Epoch 129 Batch 100: Train Loss = 0.0664\n",
      "Epoch 129 Batch 120: Train Loss = 0.1023\n",
      "Epoch 129: Loss = 0.0925 Valid loss = 0.1302 roc = 0.9474\n",
      "confusion matrix:\n",
      "[[3862   56]\n",
      " [ 113  195]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9715723395347595\n",
      "precision class 1 = 0.7768924236297607\n",
      "recall class 0 = 0.9857069849967957\n",
      "recall class 1 = 0.6331169009208679\n",
      "AUC of ROC = 0.9474337556267112\n",
      "AUC of PRC = 0.7759221486330774\n",
      "min(+P, Se) = 0.7012987012987013\n",
      "f1_score = 0.6976743972410485\n",
      "Epoch 130 Batch 0: Train Loss = 0.0739\n",
      "Epoch 130 Batch 20: Train Loss = 0.0794\n",
      "Epoch 130 Batch 40: Train Loss = 0.1280\n",
      "Epoch 130 Batch 60: Train Loss = 0.0478\n",
      "Epoch 130 Batch 80: Train Loss = 0.0977\n",
      "Epoch 130 Batch 100: Train Loss = 0.0860\n",
      "Epoch 130 Batch 120: Train Loss = 0.1010\n",
      "Epoch 130: Loss = 0.0913 Valid loss = 0.1424 roc = 0.9463\n",
      "confusion matrix:\n",
      "[[3888   30]\n",
      " [ 134  174]]\n",
      "accuracy = 0.9611926078796387\n",
      "precision class 0 = 0.9666832685470581\n",
      "precision class 1 = 0.8529411554336548\n",
      "recall class 0 = 0.992343008518219\n",
      "recall class 1 = 0.5649350881576538\n",
      "AUC of ROC = 0.9463183574975305\n",
      "AUC of PRC = 0.7642034990502182\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6796875101281323\n",
      "Epoch 131 Batch 0: Train Loss = 0.0968\n",
      "Epoch 131 Batch 20: Train Loss = 0.0773\n",
      "Epoch 131 Batch 40: Train Loss = 0.0997\n",
      "Epoch 131 Batch 60: Train Loss = 0.1606\n",
      "Epoch 131 Batch 80: Train Loss = 0.0933\n",
      "Epoch 131 Batch 100: Train Loss = 0.0721\n",
      "Epoch 131 Batch 120: Train Loss = 0.1223\n",
      "Epoch 131: Loss = 0.0908 Valid loss = 0.1293 roc = 0.9458\n",
      "confusion matrix:\n",
      "[[3876   42]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9616658687591553\n",
      "precision class 0 = 0.9699699878692627\n",
      "precision class 1 = 0.8173912763595581\n",
      "recall class 0 = 0.9892802238464355\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9457706025470191\n",
      "AUC of PRC = 0.7708328654557673\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6988847349412297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 Batch 0: Train Loss = 0.0949\n",
      "Epoch 132 Batch 20: Train Loss = 0.0607\n",
      "Epoch 132 Batch 40: Train Loss = 0.0977\n",
      "Epoch 132 Batch 60: Train Loss = 0.0746\n",
      "Epoch 132 Batch 80: Train Loss = 0.1537\n",
      "Epoch 132 Batch 100: Train Loss = 0.0526\n",
      "Epoch 132 Batch 120: Train Loss = 0.0536\n",
      "Epoch 132: Loss = 0.0901 Valid loss = 0.1302 roc = 0.9485\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 125  183]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9687187075614929\n",
      "precision class 1 = 0.7956521511077881\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.5941558480262756\n",
      "AUC of ROC = 0.9484704295194342\n",
      "AUC of PRC = 0.7678346029290138\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6802974211464726\n",
      "Epoch 133 Batch 0: Train Loss = 0.0682\n",
      "Epoch 133 Batch 20: Train Loss = 0.1279\n",
      "Epoch 133 Batch 40: Train Loss = 0.1150\n",
      "Epoch 133 Batch 60: Train Loss = 0.0698\n",
      "Epoch 133 Batch 80: Train Loss = 0.1197\n",
      "Epoch 133 Batch 100: Train Loss = 0.0703\n",
      "Epoch 133 Batch 120: Train Loss = 0.0818\n",
      "Epoch 133: Loss = 0.0928 Valid loss = 0.1241 roc = 0.9473\n",
      "confusion matrix:\n",
      "[[3879   39]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9699925184249878\n",
      "precision class 1 = 0.8281938433647156\n",
      "recall class 0 = 0.990045964717865\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.947260562306504\n",
      "AUC of PRC = 0.77349672973994\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.7028037579722448\n",
      "Epoch 134 Batch 0: Train Loss = 0.0700\n",
      "Epoch 134 Batch 20: Train Loss = 0.0959\n",
      "Epoch 134 Batch 40: Train Loss = 0.0880\n",
      "Epoch 134 Batch 60: Train Loss = 0.0376\n",
      "Epoch 134 Batch 80: Train Loss = 0.0745\n",
      "Epoch 134 Batch 100: Train Loss = 0.1178\n",
      "Epoch 134 Batch 120: Train Loss = 0.0643\n",
      "Epoch 134: Loss = 0.0897 Valid loss = 0.1277 roc = 0.9472\n",
      "confusion matrix:\n",
      "[[3848   70]\n",
      " [ 101  207]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.974423885345459\n",
      "precision class 1 = 0.7472923994064331\n",
      "recall class 0 = 0.9821337461471558\n",
      "recall class 1 = 0.6720778942108154\n",
      "AUC of ROC = 0.947170236603621\n",
      "AUC of PRC = 0.7641641818063133\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.7076922835588925\n",
      "Epoch 135 Batch 0: Train Loss = 0.0672\n",
      "Epoch 135 Batch 20: Train Loss = 0.0774\n",
      "Epoch 135 Batch 40: Train Loss = 0.0670\n",
      "Epoch 135 Batch 60: Train Loss = 0.0810\n",
      "Epoch 135 Batch 80: Train Loss = 0.0903\n",
      "Epoch 135 Batch 100: Train Loss = 0.1107\n",
      "Epoch 135 Batch 120: Train Loss = 0.1200\n",
      "Epoch 135: Loss = 0.0900 Valid loss = 0.1226 roc = 0.9479\n",
      "confusion matrix:\n",
      "[[3856   62]\n",
      " [ 110  198]]\n",
      "accuracy = 0.9592995643615723\n",
      "precision class 0 = 0.9722642302513123\n",
      "precision class 1 = 0.7615384459495544\n",
      "recall class 0 = 0.9841756224632263\n",
      "recall class 1 = 0.6428571343421936\n",
      "AUC of ROC = 0.9478555517988903\n",
      "AUC of PRC = 0.7672046306237061\n",
      "min(+P, Se) = 0.6893203883495146\n",
      "f1_score = 0.6971830870513522\n",
      "Epoch 136 Batch 0: Train Loss = 0.1027\n",
      "Epoch 136 Batch 20: Train Loss = 0.0818\n",
      "Epoch 136 Batch 40: Train Loss = 0.0879\n",
      "Epoch 136 Batch 60: Train Loss = 0.0769\n",
      "Epoch 136 Batch 80: Train Loss = 0.0528\n",
      "Epoch 136 Batch 100: Train Loss = 0.0829\n",
      "Epoch 136 Batch 120: Train Loss = 0.0714\n",
      "Epoch 136: Loss = 0.0878 Valid loss = 0.1286 roc = 0.9453\n",
      "confusion matrix:\n",
      "[[3861   57]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.969613254070282\n",
      "precision class 1 = 0.7663934230804443\n",
      "recall class 0 = 0.9854517579078674\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9453115159470443\n",
      "AUC of PRC = 0.7537981852310398\n",
      "min(+P, Se) = 0.6893203883495146\n",
      "f1_score = 0.6775362001474963\n",
      "Epoch 137 Batch 0: Train Loss = 0.0799\n",
      "Epoch 137 Batch 20: Train Loss = 0.0891\n",
      "Epoch 137 Batch 40: Train Loss = 0.0881\n",
      "Epoch 137 Batch 60: Train Loss = 0.0911\n",
      "Epoch 137 Batch 80: Train Loss = 0.0604\n",
      "Epoch 137 Batch 100: Train Loss = 0.1325\n",
      "Epoch 137 Batch 120: Train Loss = 0.1019\n",
      "Epoch 137: Loss = 0.0896 Valid loss = 0.1236 roc = 0.9460\n",
      "confusion matrix:\n",
      "[[3869   49]\n",
      " [ 120  188]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9699172973632812\n",
      "precision class 1 = 0.7932489514350891\n",
      "recall class 0 = 0.987493634223938\n",
      "recall class 1 = 0.6103895902633667\n",
      "AUC of ROC = 0.9459951737899671\n",
      "AUC of PRC = 0.768368052790234\n",
      "min(+P, Se) = 0.6967741935483871\n",
      "f1_score = 0.6899082171063113\n",
      "Epoch 138 Batch 0: Train Loss = 0.0826\n",
      "Epoch 138 Batch 20: Train Loss = 0.0675\n",
      "Epoch 138 Batch 40: Train Loss = 0.1214\n",
      "Epoch 138 Batch 60: Train Loss = 0.1557\n",
      "Epoch 138 Batch 80: Train Loss = 0.0722\n",
      "Epoch 138 Batch 100: Train Loss = 0.1165\n",
      "Epoch 138 Batch 120: Train Loss = 0.1446\n",
      "Epoch 138: Loss = 0.0928 Valid loss = 0.1338 roc = 0.9421\n",
      "confusion matrix:\n",
      "[[3871   47]\n",
      " [ 129  179]]\n",
      "accuracy = 0.9583530426025391\n",
      "precision class 0 = 0.9677500128746033\n",
      "precision class 1 = 0.7920354008674622\n",
      "recall class 0 = 0.9880040884017944\n",
      "recall class 1 = 0.5811688303947449\n",
      "AUC of ROC = 0.9420829935761024\n",
      "AUC of PRC = 0.7472455261111814\n",
      "min(+P, Se) = 0.672077922077922\n",
      "f1_score = 0.6704119854484814\n",
      "Epoch 139 Batch 0: Train Loss = 0.1088\n",
      "Epoch 139 Batch 20: Train Loss = 0.0760\n",
      "Epoch 139 Batch 40: Train Loss = 0.0738\n",
      "Epoch 139 Batch 60: Train Loss = 0.0794\n",
      "Epoch 139 Batch 80: Train Loss = 0.0486\n",
      "Epoch 139 Batch 100: Train Loss = 0.1235\n",
      "Epoch 139 Batch 120: Train Loss = 0.0705\n",
      "Epoch 139: Loss = 0.0904 Valid loss = 0.1335 roc = 0.9438\n",
      "confusion matrix:\n",
      "[[3855   63]\n",
      " [ 115  193]]\n",
      "accuracy = 0.9578797817230225\n",
      "precision class 0 = 0.9710327386856079\n",
      "precision class 1 = 0.75390625\n",
      "recall class 0 = 0.9839203953742981\n",
      "recall class 1 = 0.6266233921051025\n",
      "AUC of ROC = 0.9438265282445987\n",
      "AUC of PRC = 0.7622222551988344\n",
      "min(+P, Se) = 0.685064935064935\n",
      "f1_score = 0.6843971723546252\n",
      "Epoch 140 Batch 0: Train Loss = 0.0873\n",
      "Epoch 140 Batch 20: Train Loss = 0.0977\n",
      "Epoch 140 Batch 40: Train Loss = 0.0706\n",
      "Epoch 140 Batch 60: Train Loss = 0.1136\n",
      "Epoch 140 Batch 80: Train Loss = 0.0859\n",
      "Epoch 140 Batch 100: Train Loss = 0.0733\n",
      "Epoch 140 Batch 120: Train Loss = 0.0644\n",
      "Epoch 140: Loss = 0.0866 Valid loss = 0.1393 roc = 0.9403\n",
      "confusion matrix:\n",
      "[[3877   41]\n",
      " [ 126  182]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9685236215591431\n",
      "precision class 1 = 0.8161435127258301\n",
      "recall class 0 = 0.9895354509353638\n",
      "recall class 1 = 0.5909090638160706\n",
      "AUC of ROC = 0.9402864236325186\n",
      "AUC of PRC = 0.761374217764702\n",
      "min(+P, Se) = 0.6967741935483871\n",
      "f1_score = 0.6854990744682845\n",
      "Epoch 141 Batch 0: Train Loss = 0.1161\n",
      "Epoch 141 Batch 20: Train Loss = 0.1218\n",
      "Epoch 141 Batch 40: Train Loss = 0.0932\n",
      "Epoch 141 Batch 60: Train Loss = 0.1189\n",
      "Epoch 141 Batch 80: Train Loss = 0.0859\n",
      "Epoch 141 Batch 100: Train Loss = 0.0848\n",
      "Epoch 141 Batch 120: Train Loss = 0.1169\n",
      "Epoch 141: Loss = 0.0907 Valid loss = 0.1335 roc = 0.9421\n",
      "confusion matrix:\n",
      "[[3861   57]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9585896730422974\n",
      "precision class 0 = 0.9703443050384521\n",
      "precision class 1 = 0.7692307829856873\n",
      "recall class 0 = 0.9854517579078674\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9421318854703233\n",
      "AUC of PRC = 0.751143859021867\n",
      "min(+P, Se) = 0.6763754045307443\n",
      "f1_score = 0.684684679167058\n",
      "Epoch 142 Batch 0: Train Loss = 0.1246\n",
      "Epoch 142 Batch 20: Train Loss = 0.0690\n",
      "Epoch 142 Batch 40: Train Loss = 0.0745\n",
      "Epoch 142 Batch 60: Train Loss = 0.0967\n",
      "Epoch 142 Batch 80: Train Loss = 0.1108\n",
      "Epoch 142 Batch 100: Train Loss = 0.0797\n",
      "Epoch 142 Batch 120: Train Loss = 0.1114\n",
      "Epoch 142: Loss = 0.0873 Valid loss = 0.1254 roc = 0.9455\n",
      "confusion matrix:\n",
      "[[3875   43]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9692346453666687\n",
      "precision class 1 = 0.8114035129547119\n",
      "recall class 0 = 0.9890249967575073\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9454764225055189\n",
      "AUC of PRC = 0.7647802372182941\n",
      "min(+P, Se) = 0.6948051948051948\n",
      "f1_score = 0.6902985130659747\n",
      "Epoch 143 Batch 0: Train Loss = 0.0829\n",
      "Epoch 143 Batch 20: Train Loss = 0.0988\n",
      "Epoch 143 Batch 40: Train Loss = 0.0749\n",
      "Epoch 143 Batch 60: Train Loss = 0.0445\n",
      "Epoch 143 Batch 80: Train Loss = 0.0836\n",
      "Epoch 143 Batch 100: Train Loss = 0.1138\n",
      "Epoch 143 Batch 120: Train Loss = 0.0492\n",
      "Epoch 143: Loss = 0.0898 Valid loss = 0.1413 roc = 0.9460\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9623757600784302\n",
      "precision class 0 = 0.9692884087562561\n",
      "precision class 1 = 0.837104082107544\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9460424083318417\n",
      "AUC of PRC = 0.7593281074453908\n",
      "min(+P, Se) = 0.6826923076923077\n",
      "f1_score = 0.69943289983725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Batch 0: Train Loss = 0.0664\n",
      "Epoch 144 Batch 20: Train Loss = 0.1037\n",
      "Epoch 144 Batch 40: Train Loss = 0.1076\n",
      "Epoch 144 Batch 60: Train Loss = 0.1036\n",
      "Epoch 144 Batch 80: Train Loss = 0.0641\n",
      "Epoch 144 Batch 100: Train Loss = 0.0626\n",
      "Epoch 144 Batch 120: Train Loss = 0.0614\n",
      "Epoch 144: Loss = 0.0891 Valid loss = 0.1373 roc = 0.9432\n",
      "confusion matrix:\n",
      "[[3880   38]\n",
      " [ 128  180]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9680638909339905\n",
      "precision class 1 = 0.8256880640983582\n",
      "recall class 0 = 0.9903011918067932\n",
      "recall class 1 = 0.5844155550003052\n",
      "AUC of ROC = 0.9431627586298337\n",
      "AUC of PRC = 0.7629678867951573\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6844106519528524\n",
      "Epoch 145 Batch 0: Train Loss = 0.0862\n",
      "Epoch 145 Batch 20: Train Loss = 0.1405\n",
      "Epoch 145 Batch 40: Train Loss = 0.0887\n",
      "Epoch 145 Batch 60: Train Loss = 0.0864\n",
      "Epoch 145 Batch 80: Train Loss = 0.0529\n",
      "Epoch 145 Batch 100: Train Loss = 0.0636\n",
      "Epoch 145 Batch 120: Train Loss = 0.0680\n",
      "Epoch 145: Loss = 0.0853 Valid loss = 0.1327 roc = 0.9447\n",
      "confusion matrix:\n",
      "[[3872   46]\n",
      " [ 121  187]]\n",
      "accuracy = 0.9604827165603638\n",
      "precision class 0 = 0.9696969985961914\n",
      "precision class 1 = 0.8025751113891602\n",
      "recall class 0 = 0.9882593154907227\n",
      "recall class 1 = 0.6071428656578064\n",
      "AUC of ROC = 0.9446825507315554\n",
      "AUC of PRC = 0.7599096712239765\n",
      "min(+P, Se) = 0.6883116883116883\n",
      "f1_score = 0.6913123622818065\n",
      "Epoch 146 Batch 0: Train Loss = 0.0651\n",
      "Epoch 146 Batch 20: Train Loss = 0.1164\n",
      "Epoch 146 Batch 40: Train Loss = 0.1265\n",
      "Epoch 146 Batch 60: Train Loss = 0.0434\n",
      "Epoch 146 Batch 80: Train Loss = 0.0911\n",
      "Epoch 146 Batch 100: Train Loss = 0.0767\n",
      "Epoch 146 Batch 120: Train Loss = 0.0599\n",
      "Epoch 146: Loss = 0.0904 Valid loss = 0.1404 roc = 0.9430\n",
      "confusion matrix:\n",
      "[[3882   36]\n",
      " [ 127  181]]\n",
      "accuracy = 0.961429238319397\n",
      "precision class 0 = 0.9683212637901306\n",
      "precision class 1 = 0.8341013789176941\n",
      "recall class 0 = 0.9908116459846497\n",
      "recall class 1 = 0.5876623392105103\n",
      "AUC of ROC = 0.942991222661973\n",
      "AUC of PRC = 0.7576360079566893\n",
      "min(+P, Se) = 0.6818181818181818\n",
      "f1_score = 0.6895238382763346\n",
      "Epoch 147 Batch 0: Train Loss = 0.0924\n",
      "Epoch 147 Batch 20: Train Loss = 0.0464\n",
      "Epoch 147 Batch 40: Train Loss = 0.0648\n",
      "Epoch 147 Batch 60: Train Loss = 0.0992\n",
      "Epoch 147 Batch 80: Train Loss = 0.0581\n",
      "Epoch 147 Batch 100: Train Loss = 0.0966\n",
      "Epoch 147 Batch 120: Train Loss = 0.0843\n",
      "Epoch 147: Loss = 0.0864 Valid loss = 0.1341 roc = 0.9426\n",
      "confusion matrix:\n",
      "[[3870   48]\n",
      " [ 123  185]]\n",
      "accuracy = 0.9595361948013306\n",
      "precision class 0 = 0.969196081161499\n",
      "precision class 1 = 0.7939913868904114\n",
      "recall class 0 = 0.9877488613128662\n",
      "recall class 1 = 0.600649356842041\n",
      "AUC of ROC = 0.9425909720702983\n",
      "AUC of PRC = 0.7543259212627309\n",
      "min(+P, Se) = 0.6785714285714286\n",
      "f1_score = 0.6839186914615216\n",
      "Epoch 148 Batch 0: Train Loss = 0.0731\n",
      "Epoch 148 Batch 20: Train Loss = 0.0402\n",
      "Epoch 148 Batch 40: Train Loss = 0.0790\n",
      "Epoch 148 Batch 60: Train Loss = 0.0513\n",
      "Epoch 148 Batch 80: Train Loss = 0.0620\n",
      "Epoch 148 Batch 100: Train Loss = 0.0931\n",
      "Epoch 148 Batch 120: Train Loss = 0.1298\n",
      "Epoch 148: Loss = 0.0857 Valid loss = 0.1298 roc = 0.9440\n",
      "confusion matrix:\n",
      "[[3867   51]\n",
      " [ 118  190]]\n",
      "accuracy = 0.9600094556808472\n",
      "precision class 0 = 0.9703889489173889\n",
      "precision class 1 = 0.7883817553520203\n",
      "recall class 0 = 0.9869831800460815\n",
      "recall class 1 = 0.6168830990791321\n",
      "AUC of ROC = 0.9439665745178762\n",
      "AUC of PRC = 0.7622440420383123\n",
      "min(+P, Se) = 0.686084142394822\n",
      "f1_score = 0.6921675710674047\n",
      "Epoch 149 Batch 0: Train Loss = 0.0940\n",
      "Epoch 149 Batch 20: Train Loss = 0.0872\n",
      "Epoch 149 Batch 40: Train Loss = 0.0728\n",
      "Epoch 149 Batch 60: Train Loss = 0.0717\n",
      "Epoch 149 Batch 80: Train Loss = 0.0953\n",
      "Epoch 149 Batch 100: Train Loss = 0.0411\n",
      "Epoch 149 Batch 120: Train Loss = 0.1275\n",
      "Epoch 149: Loss = 0.0906 Valid loss = 0.1247 roc = 0.9486\n",
      "confusion matrix:\n",
      "[[3887   31]\n",
      " [ 135  173]]\n",
      "accuracy = 0.9607193470001221\n",
      "precision class 0 = 0.9664345979690552\n",
      "precision class 1 = 0.8480392098426819\n",
      "recall class 0 = 0.9920877814292908\n",
      "recall class 1 = 0.5616883039474487\n",
      "AUC of ROC = 0.9486104757927116\n",
      "AUC of PRC = 0.7704458444928513\n",
      "min(+P, Se) = 0.7045454545454546\n",
      "f1_score = 0.6757812139694591\n",
      "auroc 0.9506\n",
      "auprc 0.7773\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_minpse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-813a397c86ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auroc %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_auroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auprc %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_auprc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'minpse %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_minpse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_minpse' is not defined"
     ]
    }
   ],
   "source": [
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "global_best = 0\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "history = []\n",
    "\n",
    "pad_token = np.zeros(33)\n",
    "# begin_time = time.time()\n",
    "best_auroc = 0\n",
    "best_auprc = 0\n",
    "best_sum = 0\n",
    "\n",
    "    \n",
    "file_name = './model/concares'\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    counter_batch = 0\n",
    "    model.train()  \n",
    "\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(train_x, train_y, train_mask_x, train_x_len, batch_size, shuffle=True)):  \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "        opt = model(batch_x, batch_lens)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "\n",
    "\n",
    "        model_loss =  BCE_Loss \n",
    "\n",
    "        loss = model_loss\n",
    "\n",
    "        epoch_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    total_train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = []\n",
    "        valid_true = []\n",
    "        valid_pred = []\n",
    "        for batch_x, batch_y, batch_mask_x, batch_lens in batch_iter(dev_x, dev_y, dev_mask_x, dev_x_len, batch_size):\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "            batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "            opt = model(batch_x, batch_lens)\n",
    "\n",
    "            BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "\n",
    "            valid_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "\n",
    "            y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "            y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "        valid_loss = np.mean(valid_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "        y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "        ret = metrics.print_metrics_binary(y_true, y_pred,verbose = 0)\n",
    "        history.append(ret)\n",
    "        #print()\n",
    "\n",
    "        print('Epoch %d: Loss = %.4f Valid loss = %.4f roc = %.4f'%(each_epoch, total_train_loss[-1], total_valid_loss[-1], ret['auroc']))\n",
    "        metrics.print_metrics_binary(y_true, y_pred)\n",
    "\n",
    "        cur_auroc = ret['auroc']\n",
    "        if cur_auroc > best_auroc:\n",
    "            best_auroc = cur_auroc\n",
    "#             best_auprc = ret['auprc']\n",
    "#             best_minpse = ret['minpse']\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name)\n",
    "            print('------------ Save best model - AUROC: %.4f ------------'%cur_auroc) \n",
    "        \n",
    "        cur_prc = ret['auprc']\n",
    "        cur_minpse = ret['minpse']\n",
    "        \n",
    "        if cur_prc > best_auprc:\n",
    "            best_auprc = cur_prc\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name+\"prc\")\n",
    "            print('\\n------------ Save best-prc model ------------\\n')\n",
    "\n",
    "        cur_sum = cur_auroc + cur_prc + cur_minpse\n",
    "    #     print(cur_sum)\n",
    "        if cur_sum > best_sum:\n",
    "            best_sum = cur_sum\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name+\"sum\")\n",
    "            print('\\n------------ Save best-sum model ------------\\n')\n",
    "\n",
    "print('auroc %.4f'%(best_auroc))\n",
    "print('auprc %.4f'%(best_auprc))\n",
    "print('minpse %.4f'%(best_minpse))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T08:15:01.265346Z",
     "start_time": "2020-05-10T08:15:01.164506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last saved model is in epoch 89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vanilla_transformer_encoder(\n",
       "  (PositionalEncoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0)\n",
       "  )\n",
       "  (GRUs): ModuleList(\n",
       "    (0): GRU(1, 32, batch_first=True)\n",
       "    (1): GRU(1, 32, batch_first=True)\n",
       "    (2): GRU(1, 32, batch_first=True)\n",
       "    (3): GRU(1, 32, batch_first=True)\n",
       "    (4): GRU(1, 32, batch_first=True)\n",
       "    (5): GRU(1, 32, batch_first=True)\n",
       "    (6): GRU(1, 32, batch_first=True)\n",
       "    (7): GRU(1, 32, batch_first=True)\n",
       "    (8): GRU(1, 32, batch_first=True)\n",
       "    (9): GRU(1, 32, batch_first=True)\n",
       "    (10): GRU(1, 32, batch_first=True)\n",
       "    (11): GRU(1, 32, batch_first=True)\n",
       "    (12): GRU(1, 32, batch_first=True)\n",
       "    (13): GRU(1, 32, batch_first=True)\n",
       "    (14): GRU(1, 32, batch_first=True)\n",
       "    (15): GRU(1, 32, batch_first=True)\n",
       "    (16): GRU(1, 32, batch_first=True)\n",
       "    (17): GRU(1, 32, batch_first=True)\n",
       "    (18): GRU(1, 32, batch_first=True)\n",
       "    (19): GRU(1, 32, batch_first=True)\n",
       "    (20): GRU(1, 32, batch_first=True)\n",
       "    (21): GRU(1, 32, batch_first=True)\n",
       "    (22): GRU(1, 32, batch_first=True)\n",
       "    (23): GRU(1, 32, batch_first=True)\n",
       "    (24): GRU(1, 32, batch_first=True)\n",
       "    (25): GRU(1, 32, batch_first=True)\n",
       "    (26): GRU(1, 32, batch_first=True)\n",
       "    (27): GRU(1, 32, batch_first=True)\n",
       "    (28): GRU(1, 32, batch_first=True)\n",
       "    (29): GRU(1, 32, batch_first=True)\n",
       "    (30): GRU(1, 32, batch_first=True)\n",
       "    (31): GRU(1, 32, batch_first=True)\n",
       "    (32): GRU(1, 32, batch_first=True)\n",
       "  )\n",
       "  (FinalAttentionQKV): FinalAttentionQKV(\n",
       "    (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_out): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (tanh): Tanh()\n",
       "    (softmax): Softmax()\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (MultiHeadedAttention): MultiHeadedAttention(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (final_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (softmax): Softmax()\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (SublayerConnection): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (PositionwiseFeedForward): PositionwiseFeedForward(\n",
       "    (w_1): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (w_2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (demo_proj_main): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (demo_proj): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (tanh): Tanh()\n",
       "  (softmax): Softmax()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(file_name+'')\n",
    "save_epoch = checkpoint['epoch']\n",
    "print(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T08:15:06.122611Z",
     "start_time": "2020-05-10T08:15:01.322630Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubicomp/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Test Loss = 0.1431\n",
      "\n",
      "==>Predicting on test\n",
      "Test Loss = 0.1122\n",
      "confusion matrix:\n",
      "[[3701   40]\n",
      " [ 112  182]]\n",
      "accuracy = 0.962329626083374\n",
      "precision class 0 = 0.9706268310546875\n",
      "precision class 1 = 0.8198198080062866\n",
      "recall class 0 = 0.9893076419830322\n",
      "recall class 1 = 0.6190476417541504\n",
      "AUC of ROC = 0.9558141353306894\n",
      "AUC of PRC = 0.7838274764292477\n",
      "min(+P, Se) = 0.711864406779661\n",
      "f1_score = 0.7054263669584423\n"
     ]
    }
   ],
   "source": [
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(test_x, test_y, test_mask_x, test_x_len, batch_size, shuffle=True)):  \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt= model(batch_x, batch_lens)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "\n",
    "        model_loss =  BCE_Loss \n",
    "\n",
    "        loss = model_loss\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        if step % 20 == 0:\n",
    "            print('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "        y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "print(\"\\n==>Predicting on test\")\n",
    "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "test_res = metrics.print_metrics_binary(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
